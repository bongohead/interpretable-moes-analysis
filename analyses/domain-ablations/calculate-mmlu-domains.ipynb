{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ab5d74",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# This file calculates ablation targets using MMLU data. Run after running `run-base-mmlu.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f72dd9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Load libs ----\n",
    "library(tidyverse)\n",
    "library(slider)\n",
    "library(IRdisplay, include.only = 'display')\n",
    "library(IRkernel)\n",
    "\n",
    "model_prefix = 'qwen3moe'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dfaefc",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17572862",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Load data ----\n",
    "local({\n",
    "\n",
    "    raw_sample_df =\n",
    "        data.table::fread(str_glue('data/{model_prefix}/train_samples.csv'), strip.white = F) %>%\n",
    "        arrange(q_ix, token_ix) %>%\n",
    "        mutate(., shifted_token_ix = 1:n(), .by = c('q_ix'))\n",
    "    \n",
    "    raw_topk_df = data.table::fread(str_glue('data/{model_prefix}/train_topks.csv'))\n",
    "\n",
    "    last_shared_tok =\n",
    "        raw_sample_df %>%\n",
    "        group_by(shifted_token_ix, token) %>%\n",
    "        summarize(., n_questions_with_token_ix_tok = n(), .groups = 'drop') %>% \n",
    "        filter(., n_questions_with_token_ix_tok == length(unique(raw_sample_df$q_ix))) %>%\n",
    "        .$shifted_token_ix %>%\n",
    "        max\n",
    "\n",
    "    sample_df =\n",
    "        raw_sample_df %>%\n",
    "        filter(., shifted_token_ix > last_shared_tok)\n",
    "\n",
    "    topk_df = raw_topk_df %>% inner_join(select(sample_df, q_ix, token_ix), by = c('q_ix', 'token_ix'))\n",
    "\n",
    "    topk1_df = topk_df %>% filter(., topk_ix == 1) %>% select(-topk_ix)\n",
    "\n",
    "    sample_df <<- sample_df\n",
    "    topk_df <<- topk_df\n",
    "    topk1_df <<- topk1_df\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1f8c2b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Diagnostic checks ----\n",
    "domain_lang_map =\n",
    "    sample_df %>%\n",
    "    group_by(domain, lang) %>% \n",
    "    summarize(., n_tokens = n(), .groups = 'drop')\n",
    "\n",
    "print(domain_lang_map)\n",
    "\n",
    "print(sort(unique(topk1_df$expert)))\n",
    "print(sort(unique(topk1_df$layer_ix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a8bd1b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Check accuracy baselines ----\n",
    "base_accs =\n",
    "    sample_df %>%\n",
    "    group_by(domain, lang, q_ix, question_output_token, answer_char) %>% \n",
    "    summarize(tokens_per_question = n(), .groups = 'drop') %>%\n",
    "    mutate(., is_correct = ifelse(str_squish(question_output_token) == answer_char, 1, 0)) %>%\n",
    "    group_by(domain, lang) %>%\n",
    "    summarize(base_acc = sum(is_correct)/n(), questions = n(), total_tokens = sum(tokens_per_question), .groups = 'drop')\n",
    "\n",
    "print(base_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb32324e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Check accuracy by question ----\n",
    "question_accs =\n",
    "    sample_df %>%\n",
    "    group_by(domain, lang, q_ix, question_output_token, answer_char) %>% \n",
    "    summarize(tokens_per_question = n(), .groups = 'drop') %>%\n",
    "    mutate(., is_correct = ifelse(str_squish(question_output_token) == answer_char, 1, 0)) %>%\n",
    "    select(q_ix, is_correct) \n",
    "\n",
    "q_ix_correct = question_accs %>% filter(is_correct == 1) %>% .$q_ix\n",
    "# write_csv(question_accs, str_glue('data/{model_prefix}/question_accs.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d65728",
   "metadata": {},
   "source": [
    "## Ablation method 1: most common transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9165515a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Get a (token, path) level dataframe ----\n",
    "toks_with_paths =\n",
    "    topk1_df %>%\n",
    "    select(., layer_ix, q_ix, token_ix, expert) %>%\n",
    "    group_by(., q_ix, token_ix) %>%\n",
    "    arrange(., layer_ix, .by_group = T) %>%\n",
    "    mutate(\n",
    "        path = slide(expert, .f = \\(x) x, .before = 1, .after = 0),\n",
    "        layers = slide(layer_ix, .f = \\(x) x, .before = 1, .after = 0)\n",
    "    ) %>%\n",
    "    ungroup() %>%\n",
    "    filter(., layer_ix > 0) %>%\n",
    "    left_join(., select(sample_df, q_ix, token_ix, domain, lang), by = c('q_ix', 'token_ix'))\n",
    "\n",
    "head(toks_with_paths, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f927f51f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Check diagnostics ----\n",
    "cat('# Samples: ', nrow(sample_df))\n",
    "cat('\\n# Topk1 Experts (n_layers x samples): ', nrow(topk1_df))\n",
    "cat('\\n# Paths ((n_layers - 1) x samples): ', nrow(toks_with_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5840fdf",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Get a (domain, path) level dataframe with counts ----\n",
    "dom_x_path =\n",
    "    toks_with_paths %>%\n",
    "    group_by(., domain, lang, path, layers) %>%\n",
    "    summarize(., n_samples = n(), .groups = 'drop')\n",
    "\n",
    "head(dom_x_path, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4674ae0d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Get a (domain) level dataframe with token counts ----\n",
    "dom_tok_counts =\n",
    "    dom_x_path %>%\n",
    "    group_by(., domain, lang) %>%\n",
    "    summarize(., n_tok_samples = sum(n_samples), .groups = 'drop') %>%\n",
    "    mutate(., n_tok_prop = n_tok_samples/sum(n_tok_samples))\n",
    "\n",
    "dom_tok_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ec8759",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- For each target_domain x target_lang x target_k, get the specialized paths ----\n",
    "targets =\n",
    "    distinct(sample_df, domain, lang) %>%\n",
    "    expand_grid(k = c(2, 4)) %>%\n",
    "    rename(target_domain = domain, target_lang = lang, target_k = k)\n",
    "\n",
    "dom_x_path %>%\n",
    "    pivot_wider(., id_cols = c(layers, path), names_from = c(domain, lang), values_from = n_samples, values_fill = 0) %>% \n",
    "    print()\n",
    "\n",
    "spec_paths = \n",
    "    dom_x_path %>%\n",
    "    group_by(layers, path) %>%\n",
    "    mutate(., prop_of_samples = n_samples/sum(n_samples)) %>%\n",
    "    ungroup() %>%\n",
    "    expand_grid(targets, .) %>%\n",
    "    filter(domain == target_domain & lang == target_lang) %>%\n",
    "    left_join(dom_tok_counts, by = c('domain', 'lang')) %>%\n",
    "    filter(., prop_of_samples >= n_tok_prop * target_k)\n",
    "\n",
    "spec_paths_bio_en = spec_paths %>% filter(target_domain == 'biology' & target_lang == 'en' & target_k == 4)\n",
    "\n",
    "cat('Unique path counts: ', nrow(spec_paths_bio_en))\n",
    "cat('\\nPaths taken counts: ', sum(spec_paths_bio_en$n_samples), ' of ', sum(filter(dom_x_path, domain == 'biology' & lang == 'en')$n_samples))\n",
    "head(spec_paths_bio_en, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8d4626",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- For each target_domain x target_lang x target_k, get various summary stats on the ablation %s ----\n",
    "\n",
    "ablation_props = map(group_split(spec_paths, target_domain, target_lang, target_k), .progress = T, function(df_for_target) {\n",
    "    \n",
    "    props = \n",
    "        toks_with_paths %>%\n",
    "        left_join(transmute(df_for_target, layers, path, is_spec = 1), by = c('path', 'layers')) %>%\n",
    "        mutate(., is_spec = ifelse(!is.na(is_spec), 1, 0)) %>%\n",
    "        group_by(q_ix, token_ix, domain, lang) %>%\n",
    "        summarize(., n_spec_paths = sum(is_spec), n_possible_paths = n(), .groups = 'drop') %>%\n",
    "        group_by(domain, lang) %>%\n",
    "        summarize(\n",
    "            n_questions = n_distinct(q_ix),\n",
    "            n_toks = n(),\n",
    "            n_toks_with_any_spec_path = sum(ifelse(n_spec_paths > 0, 1, 0)),\n",
    "            n_toks_with_half_spec_path = sum(ifelse(n_spec_paths >= n_possible_paths * .5, 1, 0)),\n",
    "            n_spec_paths = sum(n_spec_paths),\n",
    "            n_possible_paths = sum(n_possible_paths),\n",
    "            .groups = 'drop'\n",
    "        ) %>%\n",
    "        mutate(\n",
    "            .,\n",
    "            prop_spec_paths = n_spec_paths/n_possible_paths,\n",
    "            prop_toks_with_any_spec_path = n_toks_with_any_spec_path/n_toks,\n",
    "            prop_toks_with_half_spec_path = n_toks_with_half_spec_path/n_toks\n",
    "        )\n",
    "    \n",
    "    list(\n",
    "        target_domain = df_for_target$target_domain[[1]],\n",
    "        target_lang = df_for_target$target_lang[[1]],\n",
    "        target_k = df_for_target$target_k[[1]],\n",
    "        props = props\n",
    "        )\n",
    "    })\n",
    "\n",
    "cat('Bio_en, k=2')\n",
    "ablation_props %>% keep(., \\(x) x$target_domain == 'biology' && x$target_lang == 'en' && x$target_k == 2) %>% .[[1]] %>% .$props %>% display()\n",
    "\n",
    "cat('Bio_en, k=4')\n",
    "ablation_props %>% keep(., \\(x) x$target_domain == 'biology' && x$target_lang == 'en' && x$target_k == 4) %>% .[[1]] %>% .$props %>% display()\n",
    "\n",
    "cat('CS, k=2')\n",
    "ablation_props %>% keep(., \\(x) x$target_domain == 'compsci' && x$target_lang == 'en' && x$target_k == 2) %>% .[[1]] %>% .$props %>% display()\n",
    "\n",
    "cat('CS, k=4')\n",
    "ablation_props %>% keep(., \\(x) x$target_domain == 'compsci' && x$target_lang == 'en' && x$target_k == 4) %>% .[[1]] %>% .$props %>% display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8440763",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- For each target_domain x target_lang x target_k, save JSON str ----\n",
    "\n",
    "# We save it in format\n",
    "# {\n",
    "#     layer: [\n",
    "#         [prefix, target_e]\n",
    "#         ...\n",
    "#     ]\n",
    "# }\n",
    "spec_paths_exportable = map(group_split(spec_paths, target_domain, target_lang, target_k), .progress = T, function(spec_df_for_target) {\n",
    "\n",
    "    target_domain = spec_df_for_target$target_domain[[1]]\n",
    "    target_lang = spec_df_for_target$target_lang[[1]]\n",
    "    target_k = spec_df_for_target$target_k[[1]]\n",
    "\n",
    "    spec_paths_str =\n",
    "        spec_df_for_target %>%\n",
    "        mutate(\n",
    "            target_layer = map_int(layers, \\(x) tail(x, 1)),\n",
    "            target_expert = map_int(path, \\(x) tail(x, 1)),\n",
    "            expert_prefix = map(path, \\(x) head(x, -1)),\n",
    "            rule_pair = map2(expert_prefix, target_expert, \\(x, y) list(x, y))\n",
    "        ) %>%\n",
    "        select(target_layer, rule_pair) %>%\n",
    "        group_by(., target_layer) %>%\n",
    "        summarize(\n",
    "            rules = list(rule_pair),\n",
    "            .groups = 'drop'\n",
    "        ) %>%\n",
    "        {setNames(.$rules, .$target_layer)}\n",
    "\n",
    "    jsonlite::toJSON(spec_paths_str, simplifyVector = F, auto_unbox = T, pretty = F) %>%\n",
    "        writeLines(., str_glue('data/{model_prefix}/path_ablation_targets_{target_domain}_{target_lang}_{target_k}.json'))\n",
    "\n",
    "    list(\n",
    "        target_domain = target_domain,\n",
    "        target_lang = target_lang,\n",
    "        target_k = target_k,\n",
    "        spec_paths_str = spec_paths_str\n",
    "    )\n",
    "})\n",
    "\n",
    "spec_paths_exportable %>% keep(., \\(x) x$target_domain == 'biology' && x$target_lang == 'en' && x$target_k == 2) %>% .[[1]] %>% .$spec_paths_str %>% .[[1]] %>% length()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf94dc5",
   "metadata": {},
   "source": [
    "## Ablation method 2: within-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d448606d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Get a (token, expert) level dataframe ----\n",
    "toks_with_expert =\n",
    "    topk1_df %>%\n",
    "    group_by(., q_ix, token_ix, layer_ix, expert) %>%\n",
    "    summarize(., n_samples = n(), .groups = 'drop') %>%\n",
    "    left_join(., select(sample_df, q_ix, token_ix, domain, lang), by = c('q_ix', 'token_ix'))\n",
    "\n",
    "head(toks_with_expert, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238d6e77",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Get (domain, expert) level dataframe ----\n",
    "dom_x_expert =\n",
    "    toks_with_expert %>%\n",
    "    group_by(., domain, lang, layer_ix, expert) %>%\n",
    "    summarize(., n_samples = n(), .groups = 'drop')\n",
    "\n",
    "head(dom_x_expert, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febbd926",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Get (domain) level dataframe with counts of token usage ----\n",
    "dom_full_tok_counts =\n",
    "    dom_x_expert %>%\n",
    "    group_by(., domain, lang) %>%\n",
    "    summarize(., n_tok_samples = sum(n_samples), .groups = 'drop') %>%\n",
    "    mutate(., n_tok_prop = n_tok_samples/sum(n_tok_samples))\n",
    "\n",
    "dom_full_tok_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277380d4",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Get specialized experts for each (target) ----\n",
    "dom_x_expert %>%\n",
    "    pivot_wider(., id_cols = c(layer_ix, expert), names_from = c(domain, lang), values_from = n_samples, values_fill = 0) %>% \n",
    "    print()\n",
    "\n",
    "spec_experts =\n",
    "    dom_x_expert %>%\n",
    "    group_by(layer_ix, expert) %>%\n",
    "    mutate(., prop_of_samples = n_samples/sum(n_samples)) %>%\n",
    "    ungroup() %>%\n",
    "    expand_grid(targets, .) %>%\n",
    "    filter(domain == target_domain & lang == target_lang) %>%\n",
    "    left_join(dom_full_tok_counts, by = c('domain', 'lang')) %>%\n",
    "    filter(., prop_of_samples >= n_tok_prop * target_k)\n",
    "\n",
    "spec_experts_bio_en = spec_experts %>% filter(target_domain == 'biology' & target_lang == 'en' & target_k == 4)\n",
    "\n",
    "cat('Unique expert counts: ', nrow(spec_experts_bio_en))\n",
    "cat('\\nExperts taken counts: ', sum(spec_experts_bio_en$n_samples), ' of ', sum(filter(dom_x_path, domain == 'biology' & lang == 'en')$n_samples))\n",
    "head(spec_experts_bio_en, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63815292",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- For each target_domain x target_lang x target_k, get various summary stats on the ablation %s ----\n",
    "expert_ablation_props = map(group_split(spec_experts, target_domain, target_lang, target_k), .progress = T, function(df_for_target) {\n",
    "    \n",
    "    props = \n",
    "        toks_with_expert %>%\n",
    "        left_join(transmute(df_for_target, layer_ix, expert, is_spec = 1), by = c('layer_ix', 'expert')) %>%\n",
    "        mutate(., is_spec = ifelse(!is.na(is_spec), 1, 0)) %>%\n",
    "        group_by(q_ix, token_ix, domain, lang) %>%\n",
    "        summarize(., n_spec_exps = sum(is_spec), n_possible_exps = n(), .groups = 'drop') %>%\n",
    "        group_by(domain, lang) %>%\n",
    "        summarize(\n",
    "            n_questions = n_distinct(q_ix),\n",
    "            n_toks = n(),\n",
    "            n_toks_with_any_spec_exp = sum(ifelse(n_spec_exps > 0, 1, 0)),\n",
    "            n_toks_with_half_spec_exp = sum(ifelse(n_spec_exps >= n_possible_exps * .5, 1, 0)),\n",
    "            n_spec_exps = sum(n_spec_exps),\n",
    "            n_possible_exps = sum(n_possible_exps),\n",
    "            .groups = 'drop'\n",
    "        ) %>%\n",
    "        mutate(\n",
    "            .,\n",
    "            prop_spec_exps = n_spec_exps/n_possible_exps,\n",
    "            prop_toks_with_any_spec_exp = n_toks_with_any_spec_exp/n_toks,\n",
    "            prop_toks_with_half_spec_exp = n_toks_with_half_spec_exp/n_toks\n",
    "        )\n",
    "    \n",
    "    list(\n",
    "        target_domain = df_for_target$target_domain[[1]],\n",
    "        target_lang = df_for_target$target_lang[[1]],\n",
    "        target_k = df_for_target$target_k[[1]],\n",
    "        props = props\n",
    "        )\n",
    "    })\n",
    "\n",
    "cat('Bio_en, k=2')\n",
    "expert_ablation_props %>% keep(., \\(x) x$target_domain == 'biology' && x$target_lang == 'en' && x$target_k == 2) %>% .[[1]] %>% .$props %>% display()\n",
    "\n",
    "cat('Bio_en, k=4')\n",
    "expert_ablation_props %>% keep(., \\(x) x$target_domain == 'biology' && x$target_lang == 'en' && x$target_k == 4) %>% .[[1]] %>% .$props %>% display()\n",
    "\n",
    "cat('CS, k=2')\n",
    "expert_ablation_props %>% keep(., \\(x) x$target_domain == 'compsci' && x$target_lang == 'en' && x$target_k == 2) %>% .[[1]] %>% .$props %>% display()\n",
    "\n",
    "cat('CS, k=4')\n",
    "expert_ablation_props %>% keep(., \\(x) x$target_domain == 'compsci' && x$target_lang == 'en' && x$target_k == 4) %>% .[[1]] %>% .$props %>% display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe12c05",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- For each target_domain x target_lang x target_k, save JSON str ----\n",
    "\n",
    "# We save it in format\n",
    "# {\n",
    "#     layer: [expert1, expert2],\n",
    "# }\n",
    "spec_experts_exportable = map(group_split(spec_experts, target_domain, target_lang, target_k), .progress = T, function(spec_df_for_target) {\n",
    "\n",
    "    target_domain = spec_df_for_target$target_domain[[1]]\n",
    "    target_lang = spec_df_for_target$target_lang[[1]]\n",
    "    target_k = spec_df_for_target$target_k[[1]]\n",
    "\n",
    "    spec_experts_str =\n",
    "        spec_df_for_target %>%\n",
    "        group_by(., layer_ix) %>%\n",
    "        summarize(\n",
    "            expert = list(expert),\n",
    "            .groups = 'drop'\n",
    "        ) %>% \n",
    "        filter(layer_ix > 0) %>%\n",
    "        {setNames(.$expert, .$layer_ix)}\n",
    "\n",
    "    jsonlite::toJSON(spec_experts_str, simplifyVector = F, auto_unbox = T, pretty = F) %>%\n",
    "        writeLines(., str_glue('data/{model_prefix}/expert_ablation_targets_{target_domain}_{target_lang}_{target_k}.json'))\n",
    "\n",
    "    list(\n",
    "        target_domain = target_domain,\n",
    "        target_lang = target_lang,\n",
    "        target_k = target_k,\n",
    "        spec_experts_str = spec_experts_str\n",
    "    )\n",
    "})\n",
    "\n",
    "spec_experts_exportable %>% keep(., \\(x) x$target_domain == 'biology' && x$target_lang == 'en' && x$target_k == 2) %>% .[[1]] %>% .$spec_experts_str %>% .[[1]] %>% length()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7553638f",
   "metadata": {},
   "source": [
    "## Ablation method 3: 4-layer paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336058d3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Get a (token, path) level dataframe ----\n",
    "multipath_length = 2\n",
    "\n",
    "toks_with_multipaths =\n",
    "    topk1_df %>%\n",
    "    select(., layer_ix, q_ix, token_ix, expert) %>%\n",
    "    group_by(., q_ix, token_ix) %>%\n",
    "    arrange(., layer_ix, .by_group = T) %>%\n",
    "    mutate(\n",
    "        path = slide(expert, .f = \\(x) x, .before = multipath_length, .after = 0),\n",
    "        layers = slide(layer_ix, .f = \\(x) x, .before = multipath_length, .after = 0)\n",
    "    ) %>%\n",
    "    ungroup() %>%\n",
    "    filter(., layer_ix > multipath_length - 1) %>%\n",
    "    left_join(., select(sample_df, q_ix, token_ix, domain, lang), by = c('q_ix', 'token_ix'))\n",
    "\n",
    "head(toks_with_multipaths, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ad1071",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Get a (domain, path) level dataframe with counts ----\n",
    "dom_x_multipath =\n",
    "    toks_with_multipaths %>%\n",
    "    group_by(., domain, lang, path, layers) %>%\n",
    "    summarize(., n_samples = n(), .groups = 'drop')\n",
    "\n",
    "head(dom_x_multipath, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eb438d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- Get a (domain) level dataframe with token counts ----\n",
    "dom_multipath_tok_counts =\n",
    "    dom_x_multipath %>%\n",
    "    group_by(., domain, lang) %>%\n",
    "    summarize(., n_tok_samples = sum(n_samples), .groups = 'drop') %>%\n",
    "    mutate(., n_tok_prop = n_tok_samples/sum(n_tok_samples))\n",
    "\n",
    "dom_multipath_tok_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0f03dd",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- For each target_domain x target_lang x target_k, get the specialized paths ----\n",
    "targets =\n",
    "    distinct(sample_df, domain, lang) %>%\n",
    "    expand_grid(k = c(2, 4)) %>%\n",
    "    rename(target_domain = domain, target_lang = lang, target_k = k)\n",
    "\n",
    "dom_x_multipath %>%\n",
    "    pivot_wider(., id_cols = c(layers, path), names_from = c(domain, lang), values_from = n_samples, values_fill = 0) %>% \n",
    "    print()\n",
    "\n",
    "spec_multipaths = \n",
    "    dom_x_multipath %>%\n",
    "    group_by(layers, path) %>%\n",
    "    mutate(., prop_of_samples = n_samples/sum(n_samples)) %>%\n",
    "    ungroup() %>%\n",
    "    expand_grid(targets, .) %>%\n",
    "    filter(domain == target_domain & lang == target_lang) %>%\n",
    "    left_join(dom_multipath_tok_counts, by = c('domain', 'lang')) %>%\n",
    "    filter(., prop_of_samples >= n_tok_prop * target_k)\n",
    "\n",
    "spec_multipaths_bio_en = spec_multipaths %>% filter(target_domain == 'biology' & target_lang == 'en' & target_k == 4)\n",
    "\n",
    "cat('Unique path counts: ', nrow(spec_multipaths_bio_en))\n",
    "cat('\\nPaths taken counts: ', sum(spec_multipaths_bio_en$n_samples), ' of ', sum(filter(dom_x_multipath, domain == 'biology' & lang == 'en')$n_samples))\n",
    "head(spec_multipaths_bio_en, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6395bf16",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- For each target_domain x target_lang x target_k, get various summary stats on the ablation %s ----\n",
    "\n",
    "ablation_multipath_props = map(group_split(spec_multipaths, target_domain, target_lang, target_k), .progress = T, function(df_for_target) {\n",
    "    \n",
    "    props = \n",
    "        toks_with_multipaths %>%\n",
    "        left_join(transmute(df_for_target, layers, path, is_spec = 1), by = c('path', 'layers')) %>%\n",
    "        mutate(., is_spec = ifelse(!is.na(is_spec), 1, 0)) %>%\n",
    "        group_by(q_ix, token_ix, domain, lang) %>%\n",
    "        summarize(., n_spec_paths = sum(is_spec), n_possible_paths = n(), .groups = 'drop') %>%\n",
    "        group_by(domain, lang) %>%\n",
    "        summarize(\n",
    "            n_questions = n_distinct(q_ix),\n",
    "            n_toks = n(),\n",
    "            n_toks_with_any_spec_path = sum(ifelse(n_spec_paths > 0, 1, 0)),\n",
    "            n_toks_with_half_spec_path = sum(ifelse(n_spec_paths >= n_possible_paths * .5, 1, 0)),\n",
    "            n_spec_paths = sum(n_spec_paths),\n",
    "            n_possible_paths = sum(n_possible_paths),\n",
    "            .groups = 'drop'\n",
    "        ) %>%\n",
    "        mutate(\n",
    "            .,\n",
    "            prop_spec_paths = n_spec_paths/n_possible_paths,\n",
    "            prop_toks_with_any_spec_path = n_toks_with_any_spec_path/n_toks,\n",
    "            prop_toks_with_half_spec_path = n_toks_with_half_spec_path/n_toks\n",
    "        )\n",
    "    \n",
    "    list(\n",
    "        target_domain = df_for_target$target_domain[[1]],\n",
    "        target_lang = df_for_target$target_lang[[1]],\n",
    "        target_k = df_for_target$target_k[[1]],\n",
    "        props = props\n",
    "        )\n",
    "    })\n",
    "\n",
    "cat('Bio_en, k=2')\n",
    "ablation_multipath_props %>% keep(., \\(x) x$target_domain == 'biology' && x$target_lang == 'en' && x$target_k == 2) %>% .[[1]] %>% .$props %>% display()\n",
    "\n",
    "cat('Bio_en, k=4')\n",
    "ablation_multipath_props %>% keep(., \\(x) x$target_domain == 'biology' && x$target_lang == 'en' && x$target_k == 4) %>% .[[1]] %>% .$props %>% display()\n",
    "\n",
    "cat('CS, k=2')\n",
    "ablation_multipath_props %>% keep(., \\(x) x$target_domain == 'compsci' && x$target_lang == 'en' && x$target_k == 2) %>% .[[1]] %>% .$props %>% display()\n",
    "\n",
    "cat('CS, k=4')\n",
    "ablation_multipath_props %>% keep(., \\(x) x$target_domain == 'compsci' && x$target_lang == 'en' && x$target_k == 4) %>% .[[1]] %>% .$props %>% display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc782f2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---- For each target_domain x target_lang x target_k, save JSON str ----\n",
    "\n",
    "# We save it in format\n",
    "# {\n",
    "#     layer: [\n",
    "#         [prefix, target_e]\n",
    "#         ...\n",
    "#     ]\n",
    "# }\n",
    "spec_multipaths_exportable = map(group_split(spec_multipaths, target_domain, target_lang, target_k), .progress = T, function(spec_df_for_target) {\n",
    "\n",
    "    target_domain = spec_df_for_target$target_domain[[1]]\n",
    "    target_lang = spec_df_for_target$target_lang[[1]]\n",
    "    target_k = spec_df_for_target$target_k[[1]]\n",
    "\n",
    "    spec_multipaths_str =\n",
    "        spec_df_for_target %>%\n",
    "        # filter(., n_samples >= 2) %>%\n",
    "        mutate(\n",
    "            target_layer = map_int(layers, \\(x) tail(x, 1)),\n",
    "            target_expert = map_int(path, \\(x) tail(x, 1)),\n",
    "            expert_prefix = map(path, \\(x) head(x, -1)),\n",
    "            rule_pair = map2(expert_prefix, target_expert, \\(x, y) list(x, y))\n",
    "        ) %>%\n",
    "        select(target_layer, rule_pair) %>%\n",
    "        group_by(., target_layer) %>%\n",
    "        summarize(\n",
    "            rules = list(rule_pair),\n",
    "            .groups = 'drop'\n",
    "        ) %>%\n",
    "        {setNames(.$rules, .$target_layer)}\n",
    "\n",
    "    jsonlite::toJSON(spec_multipaths_str, simplifyVector = F, auto_unbox = T, pretty = F) %>%\n",
    "        writeLines(., str_glue('data/{model_prefix}/multipath_ablation_targets_{target_domain}_{target_lang}_{target_k}.json'))\n",
    "\n",
    "    list(\n",
    "        target_domain = target_domain,\n",
    "        target_lang = target_lang,\n",
    "        target_k = target_k,\n",
    "        spec_multipaths_str = spec_multipaths_str\n",
    "    )\n",
    "})\n",
    "\n",
    "spec_multipaths_exportable %>% keep(., \\(x) x$target_domain == 'biology' && x$target_lang == 'en' && x$target_k == 2) %>% .[[1]] %>% .$spec_multipaths_str %>% .[[4]] %>% length()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec8be7f",
   "metadata": {},
   "source": [
    "## UNUSED: Ablation method 3: within-layer, multiple experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca990488",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# # Get multi-topk [order matters!]\n",
    "# toks_with_multi_topk =\n",
    "#     topk_df %>%\n",
    "#     filter(topk_ix %in% 1:2) %>%\n",
    "#     arrange(q_ix, token_ix, layer_ix, topk_ix, expert) %>%\n",
    "#     group_by(q_ix, token_ix, layer_ix) %>%\n",
    "#     arrange(topk_ix, .by_group = T) %>% # Order matters, switch topk_ix for expert otherwise\n",
    "#     summarize(., experts = list(expert), .groups = 'drop') %>%\n",
    "#     left_join(., select(sample_df, q_ix, token_ix, domain, lang), by = c('q_ix', 'token_ix'))\n",
    "    \n",
    "# dom_x_experts = \n",
    "#     toks_with_multi_topk %>%\n",
    "#     group_by(., domain, lang, layer_ix, experts) %>%\n",
    "#     summarize(., n_samples = n(), .groups = 'drop')\n",
    "\n",
    "# print(head(topks_by_multi_topk, 5))\n",
    "\n",
    "# dom_counts =\n",
    "#     dom_x_experts %>%\n",
    "#     group_by(., domain, lang) %>%\n",
    "#     summarize(., n_tok_samples = sum(n_samples), .groups = 'drop') %>%\n",
    "#     mutate(., n_tok_prop = n_tok_samples/sum(n_tok_samples))\n",
    "\n",
    "# print(head(dom_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f462ffab",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# dom_x_experts %>%\n",
    "#     pivot_wider(., id_cols = c(layer_ix, experts), names_from = c(domain, lang), values_from = n_samples, values_fill = 0) %>% \n",
    "#     print()\n",
    "\n",
    "# spec_multi_topk =\n",
    "#     dom_x_experts %>%\n",
    "#     group_by(layer_ix, experts) %>%\n",
    "#     mutate(., prop_of_samples = n_samples/sum(n_samples)) %>%\n",
    "#     ungroup() %>%\n",
    "#     filter(., domain == test_domain & lang == test_lang) %>%\n",
    "#     left_join(dom_counts, by = c('domain', 'lang')) %>%\n",
    "#     filter(., prop_of_samples >= n_tok_prop * 5)\n",
    "\n",
    "# cat('Specialized [exp1, exp2]: ', sum(spec_multi_topk$n_samples), ' of ', sum(filter(dom_x_experts, domain == test_domain & lang == test_lang)$n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb4fe2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# # Analyze proportions to be ablated\n",
    "# toks_with_multi_topk %>%\n",
    "#     left_join(transmute(spec_multi_topk, layer_ix, experts, is_spec = 1), by = c('layer_ix', 'experts')) %>%\n",
    "#     mutate(., is_spec = ifelse(!is.na(is_spec), 1, 0)) %>%\n",
    "#     group_by(q_ix, token_ix, domain, lang) %>%\n",
    "#     summarize(., n_spec_exp_pairs = sum(is_spec), n_possible_exp_pairs = n(), .groups = 'drop') %>%\n",
    "#     group_by(domain, lang) %>%\n",
    "#     summarize(\n",
    "#         n_questions = n_distinct(q_ix),\n",
    "#         n_toks = n(),\n",
    "#         n_toks_with_any_spec_exp_pairs = sum(ifelse(n_spec_exp_pairs > 0, 1, 0)),\n",
    "#         n_toks_with_half_spec_exp_pairs = sum(ifelse(n_spec_exp_pairs >= n_possible_exp_pairs * .5, 1, 0)),\n",
    "#         n_spec_exp_pairs = sum(n_spec_exp_pairs),\n",
    "#         n_possible_exp_pairs = sum(n_possible_exp_pairs),\n",
    "#         .groups = 'drop'\n",
    "#     ) %>%\n",
    "#     mutate(\n",
    "#         .,\n",
    "#         prop_spec_exp_pairs = n_spec_exp_pairs/n_possible_exp_pairs,\n",
    "#         prop_toks_with_any_spec_exp_pairs = n_toks_with_any_spec_exp_pairs/n_toks,\n",
    "#         prop_toks_with_half_spec_exp_pairs = n_toks_with_half_spec_exp_pairs/n_toks\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
