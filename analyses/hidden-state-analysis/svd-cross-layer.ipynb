{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This contains code to use SVD to decompose hidden states based on whether they're used by routing or not.\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CUDA memory cleared on all devices.\n",
      "Device 0: NVIDIA H100 PCIe\n",
      "  Allocated: 0.00 GB\n",
      "  Reserved: 0.00 GB\n",
      "  Total: 79.10 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import cupy\n",
    "import cuml\n",
    "import sklearn\n",
    "\n",
    "import importlib\n",
    "import gc\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from termcolor import colored\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from utils.memory import check_memory, clear_all_cuda_memory\n",
    "from utils.quantize import compare_bf16_fp16_batched\n",
    "from utils.svd import decompose_orthogonal, decompose_sideways\n",
    "from utils.vis import combine_plots\n",
    "\n",
    "main_device = 'cuda:0'\n",
    "seed = 1234\n",
    "clear_all_cuda_memory()\n",
    "check_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d82d118804543baa837050f59e96ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load the base tokenizer/model\n",
    "\"\"\"\n",
    "model_ix = 2\n",
    "models_list = [\n",
    "    ('allenai/OLMoE-1B-7B-0125-Instruct', 'olmoe', 0),\n",
    "    ('Qwen/Qwen1.5-MoE-A2.7B-Chat', 'qwen1.5moe', 0),\n",
    "    ('deepseek-ai/DeepSeek-V2-Lite', 'dsv2', 1),\n",
    "    ('Qwen/Qwen3-30B-A3B', 'qwen3moe', 0)\n",
    "]\n",
    "\n",
    "model_id, model_prefix, model_pre_mlp_layers = models_list[model_ix]\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token = False, add_bos_token = False, padding_side = 'left', trust_remote_code = True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype = torch.bfloat16, trust_remote_code = True).cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:10<00:00,  5.17s/it]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load dataset\n",
    "\"\"\"\n",
    "def load_data(model_prefix, max_data_files):\n",
    "    \"\"\"\n",
    "    Load data saved by `export-activations-sm.ipynb`\n",
    "    \"\"\"\n",
    "    folders = [f'./../export-data/activations-sm/{model_prefix}/{i:02d}' for i in range(max_data_files)]\n",
    "    folders = [f for f in folders if os.path.isdir(f)]\n",
    "\n",
    "    all_pre_mlp_hs = []\n",
    "    sample_df = []\n",
    "    topk_df = []\n",
    "\n",
    "    for f in tqdm(folders):\n",
    "        sample_df.append(pd.read_pickle(f'{f}/samples.pkl'))\n",
    "        topk_df.append(pd.read_pickle(f'{f}/topks.pkl'))\n",
    "        all_pre_mlp_hs.append(torch.load(f'{f}/all-pre-mlp-hidden-states.pt'))\n",
    "\n",
    "    sample_df = pd.concat(sample_df)\n",
    "    topk_df = pd.concat(topk_df)\n",
    "    all_pre_mlp_hs = torch.concat(all_pre_mlp_hs)    \n",
    "\n",
    "    with open(f'./../export-data/activations-sm/{model_prefix}/metadata.pkl', 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    \n",
    "    gc.collect()\n",
    "    return sample_df, topk_df, all_pre_mlp_hs, metadata['all_pre_mlp_hidden_states_layers']\n",
    "\n",
    "# Due to mem constraints, for Qwen3Moe max_data_files = 2\n",
    "sample_df_import, topk_df_import, all_pre_mlp_hs_import, act_map = load_data(model_prefix, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_ix</th>\n",
       "      <th>topk_ix</th>\n",
       "      <th>expert</th>\n",
       "      <th>weight</th>\n",
       "      <th>sample_ix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24699007</th>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.07</td>\n",
       "      <td>158326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24699008</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.07</td>\n",
       "      <td>158326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24699009</th>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>0.05</td>\n",
       "      <td>158326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24699010</th>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>0.04</td>\n",
       "      <td>158326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24699011</th>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0.03</td>\n",
       "      <td>158326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24699012 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          layer_ix  topk_ix  expert  weight  sample_ix\n",
       "0                1        1      34    0.12          0\n",
       "1                1        2      29    0.10          0\n",
       "2                1        3      23    0.10          0\n",
       "3                1        4      11    0.09          0\n",
       "4                1        5      28    0.05          0\n",
       "...            ...      ...     ...     ...        ...\n",
       "24699007        26        2      32    0.07     158326\n",
       "24699008        26        3      50    0.07     158326\n",
       "24699009        26        4      51    0.05     158326\n",
       "24699010        26        5      27    0.04     158326\n",
       "24699011        26        6      12    0.03     158326\n",
       "\n",
       "[24699012 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>token_ix</th>\n",
       "      <th>token_id</th>\n",
       "      <th>output_id</th>\n",
       "      <th>output_prob</th>\n",
       "      <th>token</th>\n",
       "      <th>source</th>\n",
       "      <th>sample_ix</th>\n",
       "      <th>seq_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3942</td>\n",
       "      <td>11628</td>\n",
       "      <td>0.16</td>\n",
       "      <td>LO</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>42791</td>\n",
       "      <td>5564</td>\n",
       "      <td>0.07</td>\n",
       "      <td>QUE</td>\n",
       "      <td>es</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>417</td>\n",
       "      <td>5771</td>\n",
       "      <td>0.59</td>\n",
       "      <td>F</td>\n",
       "      <td>es</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>42549</td>\n",
       "      <td>77552</td>\n",
       "      <td>0.50</td>\n",
       "      <td>ALT</td>\n",
       "      <td>es</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>77552</td>\n",
       "      <td>185</td>\n",
       "      <td>0.18</td>\n",
       "      <td>ABA</td>\n",
       "      <td>es</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158322</th>\n",
       "      <td>81312</td>\n",
       "      <td>507</td>\n",
       "      <td>44</td>\n",
       "      <td>660</td>\n",
       "      <td>1.00</td>\n",
       "      <td>M</td>\n",
       "      <td>es</td>\n",
       "      <td>158322</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158323</th>\n",
       "      <td>81313</td>\n",
       "      <td>508</td>\n",
       "      <td>660</td>\n",
       "      <td>1708</td>\n",
       "      <td>0.98</td>\n",
       "      <td>ens</td>\n",
       "      <td>es</td>\n",
       "      <td>158323</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158324</th>\n",
       "      <td>81314</td>\n",
       "      <td>509</td>\n",
       "      <td>1708</td>\n",
       "      <td>658</td>\n",
       "      <td>1.00</td>\n",
       "      <td>aj</td>\n",
       "      <td>es</td>\n",
       "      <td>158324</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158325</th>\n",
       "      <td>81315</td>\n",
       "      <td>510</td>\n",
       "      <td>658</td>\n",
       "      <td>256</td>\n",
       "      <td>1.00</td>\n",
       "      <td>ep</td>\n",
       "      <td>es</td>\n",
       "      <td>158325</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158326</th>\n",
       "      <td>81316</td>\n",
       "      <td>511</td>\n",
       "      <td>256</td>\n",
       "      <td>284</td>\n",
       "      <td>0.33</td>\n",
       "      <td>or</td>\n",
       "      <td>es</td>\n",
       "      <td>158326</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158327 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  token_ix  token_id  output_id  output_prob token source  \\\n",
       "0           0         7      3942      11628         0.16    LO     es   \n",
       "1           1         8     42791       5564         0.07   QUE     es   \n",
       "2           2         9       417       5771         0.59     F     es   \n",
       "3           3        10     42549      77552         0.50   ALT     es   \n",
       "4           4        11     77552        185         0.18   ABA     es   \n",
       "...       ...       ...       ...        ...          ...   ...    ...   \n",
       "158322  81312       507        44        660         1.00     M     es   \n",
       "158323  81313       508       660       1708         0.98   ens     es   \n",
       "158324  81314       509      1708        658         1.00    aj     es   \n",
       "158325  81315       510       658        256         1.00    ep     es   \n",
       "158326  81316       511       256        284         0.33    or     es   \n",
       "\n",
       "        sample_ix  seq_id  \n",
       "0               0       0  \n",
       "1               1       0  \n",
       "2               2       0  \n",
       "3               3       0  \n",
       "4               4       0  \n",
       "...           ...     ...  \n",
       "158322     158322     499  \n",
       "158323     158323     499  \n",
       "158324     158324     499  \n",
       "158325     158325     499  \n",
       "158326     158326     499  \n",
       "\n",
       "[158327 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Let's clean up the mappings here. We'll get everything to a sample_ix level first.\n",
    "\"\"\"\n",
    "sample_df_raw =\\\n",
    "    sample_df_import\\\n",
    "    .assign(sample_ix = lambda df: df.groupby(['batch_ix', 'sequence_ix', 'token_ix']).ngroup())\\\n",
    "    .assign(seq_id = lambda df: df.groupby(['batch_ix', 'sequence_ix']).ngroup())\\\n",
    "    .reset_index()\n",
    "\n",
    "topk_df =\\\n",
    "    topk_df_import\\\n",
    "    .merge(sample_df_raw[['sample_ix', 'batch_ix', 'sequence_ix', 'token_ix']], how = 'inner', on = ['sequence_ix', 'token_ix', 'batch_ix'])\\\n",
    "    .drop(columns = ['sequence_ix', 'token_ix', 'batch_ix'])\\\n",
    "    .assign(layer_ix = lambda df: df['layer_ix'] + model_pre_mlp_layers)\n",
    "\n",
    "topk1_df =\\\n",
    "    topk_df\\\n",
    "    .pipe(lambda df: df[df['topk_ix'] == 1])\n",
    "\n",
    "sample_df =\\\n",
    "    sample_df_raw\\\n",
    "    .drop(columns = ['batch_ix', 'sequence_ix'])\n",
    "\n",
    "def get_sample_df_for_layer(sample_df, topk_df, layer_ix):\n",
    "    \"\"\"\n",
    "    Helper to take the sample df and merge layer-level expert selection information\n",
    "    \"\"\"\n",
    "    topk_layer_df = topk_df.pipe(lambda df: df[df['layer_ix'] == layer_ix])\n",
    "    topk_l1_layer_df = topk_df.pipe(lambda df: df[df['layer_ix'] == layer_ix - 1])\n",
    "    topk_l2_layer_df = topk_df.pipe(lambda df: df[df['layer_ix'] == layer_ix - 2])\n",
    "\n",
    "    layer_df =\\\n",
    "        sample_df\\\n",
    "        .merge(topk_layer_df.pipe(lambda df: df[df['topk_ix'] == 1])[['sample_ix', 'expert']], how = 'inner', on = 'sample_ix')\\\n",
    "        .merge(topk_l1_layer_df.pipe(lambda df: df[df['topk_ix'] == 1]).rename(columns = {'expert': 'prev_expert'})[['sample_ix', 'prev_expert']], how = 'left', on = 'sample_ix')\\\n",
    "        .merge(topk_l2_layer_df.pipe(lambda df: df[df['topk_ix'] == 1]).rename(columns = {'expert': 'prev2_expert'})[['sample_ix', 'prev2_expert']], how = 'left', on = 'sample_ix')\\\n",
    "        .merge(topk_layer_df.pipe(lambda df: df[df['topk_ix'] == 2]).rename(columns = {'expert': 'expert2'})[['sample_ix', 'expert2']], how = 'left', on = 'sample_ix')\\\n",
    "        .assign(leading_path = lambda df: df['prev2_expert'] + '-' + df['prev_expert'])\n",
    "    \n",
    "    return layer_df\n",
    "\n",
    "del sample_df_import, sample_df_raw, topk_df_import\n",
    "\n",
    "gc.collect()\n",
    "display(topk_df)\n",
    "display(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Convert activations to fp16 (for compatibility with cupy later) + dict\n",
    "\"\"\"\n",
    "all_pre_mlp_hs = all_pre_mlp_hs_import.to(torch.float16)\n",
    "# compare_bf16_fp16_batched(all_pre_mlp_hs_import, all_pre_mlp_hs)\n",
    "del all_pre_mlp_hs_import\n",
    "all_pre_mlp_hs = {(layer_ix + model_pre_mlp_layers): all_pre_mlp_hs[:, save_ix, :] for save_ix, layer_ix in enumerate(act_map)}\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:10<00:00,  2.71s/it]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Let's take the pre-MLP hidden states and split them using SVD into parallel and orthogonal components.\n",
    "\"\"\"\n",
    "h_para_by_layer = {}\n",
    "h_orth_by_layer = {}\n",
    "\n",
    "for layer_ix in tqdm(list(all_pre_mlp_hs.keys())):\n",
    "    h_para_by_layer[layer_ix], h_orth_by_layer[layer_ix] = decompose_orthogonal(\n",
    "        all_pre_mlp_hs[layer_ix].to(torch.float32),\n",
    "        model.model.layers[layer_ix].mlp.gate.weight.detach().cpu().to(torch.float32),\n",
    "        'svd'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orth vs Para Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean across layer transitions + samples: 0.53 +/- 0.11\n"
     ]
    }
   ],
   "source": [
    "bootstrap_samples = 50\n",
    "\n",
    "def get_sample_res(hs_by_layer, samples_to_test = 1):\n",
    "    \n",
    "    samples = np.random.randint(0, hs_by_layer[1].shape[0], samples_to_test)\n",
    "\n",
    "    # Cast into sample-level list\n",
    "    sample_tensors = torch.stack([layer_hs[samples, :] for _, layer_hs in hs_by_layer.items()], dim = 1).unbind(dim = 0)\n",
    "\n",
    "    sims = []\n",
    "    for s in sample_tensors:\n",
    "        cos_sim = sklearn.metrics.pairwise.cosine_similarity(s)\n",
    "        sims.append(np.diag(cos_sim, 1))\n",
    "\n",
    "    return np.mean(np.stack(sims, axis = 0), axis = 0)\n",
    "\n",
    "para_res = np.stack([get_sample_res(h_para_by_layer) for _ in range(bootstrap_samples)], axis = 0) # bootstrap_samples x layer_diffs\n",
    "\n",
    "para_mean_across_layers = para_res.mean(axis = 0)\n",
    "para_cis_across_layers = 1.96 * np.std(para_res, axis = 0)\n",
    "\n",
    "para_mean_overall = np.mean(para_mean_across_layers)\n",
    "para_mean_ci = 1.96 * np.std(np.mean(para_res, axis = 1)).item()\n",
    "\n",
    "# print(f\"Mean across layer transitions: {para_mean_across_layers}\")\n",
    "print(f\"Mean across layer transitions + samples: {para_mean_overall:.2f} +/- {para_mean_ci:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean across layer transitions + samples: 0.84 +/- 0.04\n"
     ]
    }
   ],
   "source": [
    "orth_res = np.stack([get_sample_res(h_orth_by_layer) for _ in range(bootstrap_samples)], axis = 0) # bootstrap_samples x layer_diffs\n",
    "\n",
    "orth_mean_across_layers = orth_res.mean(axis = 0)\n",
    "orth_cis_across_layers = 1.96 * np.std(orth_res, axis = 0)\n",
    "\n",
    "orth_mean_overall = np.mean(orth_mean_across_layers)\n",
    "orth_mean_ci = 1.96 * np.std(np.mean(orth_res, axis = 1)).item()\n",
    "\n",
    "# print(f\"Mean across layer transitions: {orth_mean_across_layers}\")\n",
    "print(f\"Mean across layer transitions + samples: {orth_mean_overall:.2f} +/- {orth_mean_ci:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df = pd.DataFrame({\n",
    "    'layer_ix_1': list(range(model_pre_mlp_layers + 1 + 1, len(all_pre_mlp_hs) + model_pre_mlp_layers + 1)), # +1 since these represent the transition-ends, and +1 to 1 index\n",
    "    'para_mean_across_layers': para_mean_across_layers,\n",
    "    'orth_mean_across_layers': orth_mean_across_layers,\n",
    "    'para_cis': para_cis_across_layers,\n",
    "    'orth_cis': orth_cis_across_layers\n",
    "})\n",
    "\n",
    "export_df.to_csv(f'exports/transition-stability-{model_prefix}.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction/probing tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 12/26 [00:23<00:34,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:31:25.923] [CUML] [warning] L-BFGS line search failed (code 3); stopping at the last valid step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 16/26 [00:35<00:29,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:31:37.650] [CUML] [warning] L-BFGS line search failed (code 3); stopping at the last valid step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 17/26 [00:39<00:29,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:31:41.638] [CUML] [warning] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 18/26 [00:43<00:28,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:31:46.103] [CUML] [warning] L-BFGS line search failed (code 3); stopping at the last valid step\n",
      "[2025-05-12 04:31:47.323] [CUML] [warning] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 20/26 [00:53<00:25,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:31:55.768] [CUML] [warning] L-BFGS: max iterations reached\n",
      "[2025-05-12 04:31:55.770] [CUML] [warning] Maximum iterations reached before solver is converged. To increase model accuracy you can increase the number of iterations (max_iter) or improve the scaling of the input data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 21/26 [00:58<00:22,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:32:01.012] [CUML] [warning] L-BFGS line search failed (code 3); stopping at the last valid step\n",
      "[2025-05-12 04:32:02.600] [CUML] [warning] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 22/26 [01:03<00:18,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:32:05.944] [CUML] [warning] L-BFGS: max iterations reached\n",
      "[2025-05-12 04:32:05.947] [CUML] [warning] Maximum iterations reached before solver is converged. To increase model accuracy you can increase the number of iterations (max_iter) or improve the scaling of the input data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 23/26 [01:08<00:13,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:32:10.406] [CUML] [warning] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 24/26 [01:12<00:09,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:32:14.803] [CUML] [warning] L-BFGS: max iterations reached\n",
      "[2025-05-12 04:32:14.804] [CUML] [warning] Maximum iterations reached before solver is converged. To increase model accuracy you can increase the number of iterations (max_iter) or improve the scaling of the input data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 25/26 [01:17<00:04,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:32:19.142] [CUML] [warning] L-BFGS: max iterations reached\n",
      "[2025-05-12 04:32:19.144] [CUML] [warning] Maximum iterations reached before solver is converged. To increase model accuracy you can increase the number of iterations (max_iter) or improve the scaling of the input data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:21<00:00,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:32:23.589] [CUML] [warning] L-BFGS: max iterations reached\n",
      "[2025-05-12 04:32:23.591] [CUML] [warning] Maximum iterations reached before solver is converged. To increase model accuracy you can increase the number of iterations (max_iter) or improve the scaling of the input data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_layer': 3,\n",
       "  'para_acc': 0.9633021728145528,\n",
       "  'orth_acc': 0.777033855482567},\n",
       " {'test_layer': 4,\n",
       "  'para_acc': 0.969365841334007,\n",
       "  'orth_acc': 0.6615715007579586},\n",
       " {'test_layer': 5,\n",
       "  'para_acc': 0.9692395149065185,\n",
       "  'orth_acc': 0.6445174330469934},\n",
       " {'test_layer': 6,\n",
       "  'para_acc': 0.9711344113188479,\n",
       "  'orth_acc': 0.6361798888327438},\n",
       " {'test_layer': 7,\n",
       "  'para_acc': 0.9733451237998989,\n",
       "  'orth_acc': 0.6090828701364326},\n",
       " {'test_layer': 8,\n",
       "  'para_acc': 0.9713239009600808,\n",
       "  'orth_acc': 0.5960712481051036},\n",
       " {'test_layer': 9,\n",
       "  'para_acc': 0.9739135927235978,\n",
       "  'orth_acc': 0.572321879737241},\n",
       " {'test_layer': 10,\n",
       "  'para_acc': 0.9737872662961091,\n",
       "  'orth_acc': 0.5857124810510359},\n",
       " {'test_layer': 11,\n",
       "  'para_acc': 0.9735977766548762,\n",
       "  'orth_acc': 0.5781960586154623},\n",
       " {'test_layer': 12,\n",
       "  'para_acc': 0.9733451237998989,\n",
       "  'orth_acc': 0.5608261748357757},\n",
       " {'test_layer': 13,\n",
       "  'para_acc': 0.9737872662961091,\n",
       "  'orth_acc': 0.6160308236483072},\n",
       " {'test_layer': 14,\n",
       "  'para_acc': 0.972966144517433,\n",
       "  'orth_acc': 0.5715007579585649},\n",
       " {'test_layer': 15,\n",
       "  'para_acc': 0.9797246083880747,\n",
       "  'orth_acc': 0.5654370894391106},\n",
       " {'test_layer': 16,\n",
       "  'para_acc': 0.9759348155634159,\n",
       "  'orth_acc': 0.5780065689742294},\n",
       " {'test_layer': 17,\n",
       "  'para_acc': 0.9782086912582112,\n",
       "  'orth_acc': 0.5840702374936837},\n",
       " {'test_layer': 18,\n",
       "  'para_acc': 0.9761243052046488,\n",
       "  'orth_acc': 0.5878600303183426},\n",
       " {'test_layer': 19,\n",
       "  'para_acc': 0.9777033855482566,\n",
       "  'orth_acc': 0.6022612430520465},\n",
       " {'test_layer': 20,\n",
       "  'para_acc': 0.9808615462354725,\n",
       "  'orth_acc': 0.5756695300656898},\n",
       " {'test_layer': 21,\n",
       "  'para_acc': 0.9811141990904497,\n",
       "  'orth_acc': 0.6052930773117736},\n",
       " {'test_layer': 22,\n",
       "  'para_acc': 0.9787771601819101,\n",
       "  'orth_acc': 0.6044719555330975},\n",
       " {'test_layer': 23,\n",
       "  'para_acc': 0.9814931783729156,\n",
       "  'orth_acc': 0.5898812531581606},\n",
       " {'test_layer': 24,\n",
       "  'para_acc': 0.9802299140980293,\n",
       "  'orth_acc': 0.6141359272359778},\n",
       " {'test_layer': 25,\n",
       "  'para_acc': 0.9802930773117736,\n",
       "  'orth_acc': 0.6153991915108641},\n",
       " {'test_layer': 26,\n",
       "  'para_acc': 0.9801035876705407,\n",
       "  'orth_acc': 0.6191258211217787},\n",
       " {'test_layer': 27,\n",
       "  'para_acc': 0.9804825669530066,\n",
       "  'orth_acc': 0.6507705912076807},\n",
       " {'test_layer': 28,\n",
       "  'para_acc': 0.9782086912582112,\n",
       "  'orth_acc': 0.6479282465891865}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Logistic regression - predict topk using h_orth?\n",
    "\"\"\"\n",
    "def run_lr(x_cp, y_cp):\n",
    "    x_train, x_test, y_train, y_test = cuml.train_test_split(x_cp, y_cp, test_size = 0.1, random_state = 123)\n",
    "    lr_model = cuml.linear_model.LogisticRegression(penalty = 'l2', max_iter = 1000, fit_intercept = False)\n",
    "    lr_model.fit(x_train, y_train)\n",
    "    accuracy = lr_model.score(x_test, y_test)\n",
    "    return accuracy\n",
    "\n",
    "current_layer_accuracy = []\n",
    "for test_layer in tqdm(list(h_para_by_layer.keys())):\n",
    "    expert_ids =\\\n",
    "        topk_df\\\n",
    "        .pipe(lambda df: df[df['layer_ix'] == test_layer])\\\n",
    "        .pipe(lambda df: df[df['topk_ix'] == 1])\\\n",
    "        ['expert'].tolist()\n",
    "\n",
    "    expert_ids_cp = cupy.asarray(expert_ids)\n",
    "    x_cp_para = cupy.asarray(h_para_by_layer[test_layer].to(torch.float16).detach().cpu())\n",
    "    x_cp_orth = cupy.asarray(h_orth_by_layer[test_layer].to(torch.float16).detach().cpu())\n",
    "\n",
    "    current_layer_accuracy.append({\n",
    "        'test_layer': test_layer + model_pre_mlp_layers + 1,\n",
    "        'para_acc': run_lr(x_cp_para, expert_ids_cp),\n",
    "        'orth_acc': run_lr(x_cp_orth, expert_ids_cp)\n",
    "    })\n",
    "\n",
    "current_layer_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [00:47<00:39,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:33:11.411] [CUML] [warning] L-BFGS: max iterations reached\n",
      "[2025-05-12 04:33:11.413] [CUML] [warning] Maximum iterations reached before solver is converged. To increase model accuracy you can increase the number of iterations (max_iter) or improve the scaling of the input data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [00:51<00:29,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:33:15.356] [CUML] [warning] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [00:56<00:23,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:33:19.710] [CUML] [warning] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [00:58<00:21,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:33:22.207] [CUML] [warning] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [01:04<00:18,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:33:27.692] [CUML] [warning] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [01:07<00:17,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:33:31.330] [CUML] [warning] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [01:10<00:15,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:33:34.652] [CUML] [warning] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [01:15<00:13,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:33:38.797] [CUML] [warning] L-BFGS: max iterations reached\n",
      "[2025-05-12 04:33:38.800] [CUML] [warning] Maximum iterations reached before solver is converged. To increase model accuracy you can increase the number of iterations (max_iter) or improve the scaling of the input data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [01:23<00:07,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:33:46.832] [CUML] [warning] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [01:27<00:03,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:33:50.726] [CUML] [warning] L-BFGS: max iterations reached\n",
      "[2025-05-12 04:33:50.729] [CUML] [warning] Maximum iterations reached before solver is converged. To increase model accuracy you can increase the number of iterations (max_iter) or improve the scaling of the input data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:30<00:00,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:33:54.582] [CUML] [warning] L-BFGS: max iterations reached\n",
      "[2025-05-12 04:33:54.583] [CUML] [warning] Maximum iterations reached before solver is converged. To increase model accuracy you can increase the number of iterations (max_iter) or improve the scaling of the input data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_layer': 3,\n",
       "  'para_acc': 0.46058615462354724,\n",
       "  'orth_acc': 0.6954269833249116},\n",
       " {'test_layer': 4,\n",
       "  'para_acc': 0.5368873168266801,\n",
       "  'orth_acc': 0.7076174835775644},\n",
       " {'test_layer': 5,\n",
       "  'para_acc': 0.5812910560889338,\n",
       "  'orth_acc': 0.6779939363314805},\n",
       " {'test_layer': 6,\n",
       "  'para_acc': 0.563100050530571,\n",
       "  'orth_acc': 0.6469176351692774},\n",
       " {'test_layer': 7,\n",
       "  'para_acc': 0.5716270843860536,\n",
       "  'orth_acc': 0.6489388580090955},\n",
       " {'test_layer': 8,\n",
       "  'para_acc': 0.552678120262759,\n",
       "  'orth_acc': 0.6342849924204144},\n",
       " {'test_layer': 9,\n",
       "  'para_acc': 0.5528044466902476,\n",
       "  'orth_acc': 0.6443279434057605},\n",
       " {'test_layer': 10,\n",
       "  'para_acc': 0.5862809499747347,\n",
       "  'orth_acc': 0.6362430520464881},\n",
       " {'test_layer': 11,\n",
       "  'para_acc': 0.5495199595755432,\n",
       "  'orth_acc': 0.6308741788782213},\n",
       " {'test_layer': 12,\n",
       "  'para_acc': 0.6043456291056089,\n",
       "  'orth_acc': 0.6695300656897423},\n",
       " {'test_layer': 13,\n",
       "  'para_acc': 0.5383400707427994,\n",
       "  'orth_acc': 0.654434057604851},\n",
       " {'test_layer': 14,\n",
       "  'para_acc': 0.5426983324911572,\n",
       "  'orth_acc': 0.6595502779181405},\n",
       " {'test_layer': 15,\n",
       "  'para_acc': 0.5205912076806468,\n",
       "  'orth_acc': 0.6911950480040424},\n",
       " {'test_layer': 16,\n",
       "  'para_acc': 0.5546361798888327,\n",
       "  'orth_acc': 0.7053436078827691},\n",
       " {'test_layer': 17,\n",
       "  'para_acc': 0.5612051541182416,\n",
       "  'orth_acc': 0.704711975745326},\n",
       " {'test_layer': 18,\n",
       "  'para_acc': 0.5838175846387064,\n",
       "  'orth_acc': 0.7290929762506316},\n",
       " {'test_layer': 19,\n",
       "  'para_acc': 0.5180015159171298,\n",
       "  'orth_acc': 0.7080596260737746},\n",
       " {'test_layer': 20,\n",
       "  'para_acc': 0.5702374936836786,\n",
       "  'orth_acc': 0.7308615462354725},\n",
       " {'test_layer': 21,\n",
       "  'para_acc': 0.5412455785750379,\n",
       "  'orth_acc': 0.7209449216776149},\n",
       " {'test_layer': 22,\n",
       "  'para_acc': 0.5093481556341587,\n",
       "  'orth_acc': 0.7287139969681657},\n",
       " {'test_layer': 23,\n",
       "  'para_acc': 0.5479408792319354,\n",
       "  'orth_acc': 0.7382516422435573},\n",
       " {'test_layer': 24,\n",
       "  'para_acc': 0.5439615967660435,\n",
       "  'orth_acc': 0.7287771601819101},\n",
       " {'test_layer': 25,\n",
       "  'para_acc': 0.5507832238504295,\n",
       "  'orth_acc': 0.7423572511369378},\n",
       " {'test_layer': 26,\n",
       "  'para_acc': 0.601755937342092,\n",
       "  'orth_acc': 0.7644012127337039},\n",
       " {'test_layer': 27,\n",
       "  'para_acc': 0.624810510358767,\n",
       "  'orth_acc': 0.7402728650833754}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Use h_para and h_orth to predict NEXT layer expert ids\n",
    "\"\"\"\n",
    "next_layer_accuracy = []\n",
    "for test_layer in tqdm(list(h_para_by_layer.keys())[:-1]):\n",
    "    expert_ids =\\\n",
    "        topk_df\\\n",
    "        .pipe(lambda df: df[df['layer_ix'] == test_layer + 1])\\\n",
    "        .pipe(lambda df: df[df['topk_ix'] == 1])\\\n",
    "        ['expert'].tolist()\n",
    "\n",
    "    expert_ids_cp = cupy.asarray(expert_ids)\n",
    "    x_cp_para = cupy.asarray(h_para_by_layer[test_layer].to(torch.float16).detach().cpu())\n",
    "    x_cp_orth = cupy.asarray(h_orth_by_layer[test_layer].to(torch.float16).detach().cpu())\n",
    "\n",
    "    next_layer_accuracy.append({\n",
    "        'test_layer': test_layer + model_pre_mlp_layers + 1,\n",
    "        'para_acc': run_lr(x_cp_para, expert_ids_cp),\n",
    "        'orth_acc':run_lr(x_cp_orth, expert_ids_cp)\n",
    "    })\n",
    "\n",
    "next_layer_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_layer</th>\n",
       "      <th>para_acc</th>\n",
       "      <th>orth_acc</th>\n",
       "      <th>target</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.963302</td>\n",
       "      <td>0.777034</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.969366</td>\n",
       "      <td>0.661572</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>0.644517</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.971134</td>\n",
       "      <td>0.636180</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.973345</td>\n",
       "      <td>0.609083</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>0.971324</td>\n",
       "      <td>0.596071</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0.973914</td>\n",
       "      <td>0.572322</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0.973787</td>\n",
       "      <td>0.585712</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>0.973598</td>\n",
       "      <td>0.578196</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>0.973345</td>\n",
       "      <td>0.560826</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>0.973787</td>\n",
       "      <td>0.616031</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>0.972966</td>\n",
       "      <td>0.571501</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15</td>\n",
       "      <td>0.979725</td>\n",
       "      <td>0.565437</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>0.975935</td>\n",
       "      <td>0.578007</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17</td>\n",
       "      <td>0.978209</td>\n",
       "      <td>0.584070</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "      <td>0.976124</td>\n",
       "      <td>0.587860</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>19</td>\n",
       "      <td>0.977703</td>\n",
       "      <td>0.602261</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>0.980862</td>\n",
       "      <td>0.575670</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>21</td>\n",
       "      <td>0.981114</td>\n",
       "      <td>0.605293</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>22</td>\n",
       "      <td>0.978777</td>\n",
       "      <td>0.604472</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>23</td>\n",
       "      <td>0.981493</td>\n",
       "      <td>0.589881</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>24</td>\n",
       "      <td>0.980230</td>\n",
       "      <td>0.614136</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>25</td>\n",
       "      <td>0.980293</td>\n",
       "      <td>0.615399</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>26</td>\n",
       "      <td>0.980104</td>\n",
       "      <td>0.619126</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>27</td>\n",
       "      <td>0.980483</td>\n",
       "      <td>0.650771</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>28</td>\n",
       "      <td>0.978209</td>\n",
       "      <td>0.647928</td>\n",
       "      <td>current_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.460586</td>\n",
       "      <td>0.695427</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.536887</td>\n",
       "      <td>0.707617</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.581291</td>\n",
       "      <td>0.677994</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.563100</td>\n",
       "      <td>0.646918</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.571627</td>\n",
       "      <td>0.648939</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>0.552678</td>\n",
       "      <td>0.634285</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0.552804</td>\n",
       "      <td>0.644328</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0.586281</td>\n",
       "      <td>0.636243</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>0.549520</td>\n",
       "      <td>0.630874</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>0.604346</td>\n",
       "      <td>0.669530</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>0.538340</td>\n",
       "      <td>0.654434</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>0.542698</td>\n",
       "      <td>0.659550</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15</td>\n",
       "      <td>0.520591</td>\n",
       "      <td>0.691195</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>0.554636</td>\n",
       "      <td>0.705344</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17</td>\n",
       "      <td>0.561205</td>\n",
       "      <td>0.704712</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "      <td>0.583818</td>\n",
       "      <td>0.729093</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>19</td>\n",
       "      <td>0.518002</td>\n",
       "      <td>0.708060</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>0.570237</td>\n",
       "      <td>0.730862</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>21</td>\n",
       "      <td>0.541246</td>\n",
       "      <td>0.720945</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>22</td>\n",
       "      <td>0.509348</td>\n",
       "      <td>0.728714</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>23</td>\n",
       "      <td>0.547941</td>\n",
       "      <td>0.738252</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>24</td>\n",
       "      <td>0.543962</td>\n",
       "      <td>0.728777</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>25</td>\n",
       "      <td>0.550783</td>\n",
       "      <td>0.742357</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>26</td>\n",
       "      <td>0.601756</td>\n",
       "      <td>0.764401</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>27</td>\n",
       "      <td>0.624811</td>\n",
       "      <td>0.740273</td>\n",
       "      <td>next_layer</td>\n",
       "      <td>dsv2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_layer  para_acc  orth_acc         target model\n",
       "0            3  0.963302  0.777034  current_layer  dsv2\n",
       "1            4  0.969366  0.661572  current_layer  dsv2\n",
       "2            5  0.969240  0.644517  current_layer  dsv2\n",
       "3            6  0.971134  0.636180  current_layer  dsv2\n",
       "4            7  0.973345  0.609083  current_layer  dsv2\n",
       "5            8  0.971324  0.596071  current_layer  dsv2\n",
       "6            9  0.973914  0.572322  current_layer  dsv2\n",
       "7           10  0.973787  0.585712  current_layer  dsv2\n",
       "8           11  0.973598  0.578196  current_layer  dsv2\n",
       "9           12  0.973345  0.560826  current_layer  dsv2\n",
       "10          13  0.973787  0.616031  current_layer  dsv2\n",
       "11          14  0.972966  0.571501  current_layer  dsv2\n",
       "12          15  0.979725  0.565437  current_layer  dsv2\n",
       "13          16  0.975935  0.578007  current_layer  dsv2\n",
       "14          17  0.978209  0.584070  current_layer  dsv2\n",
       "15          18  0.976124  0.587860  current_layer  dsv2\n",
       "16          19  0.977703  0.602261  current_layer  dsv2\n",
       "17          20  0.980862  0.575670  current_layer  dsv2\n",
       "18          21  0.981114  0.605293  current_layer  dsv2\n",
       "19          22  0.978777  0.604472  current_layer  dsv2\n",
       "20          23  0.981493  0.589881  current_layer  dsv2\n",
       "21          24  0.980230  0.614136  current_layer  dsv2\n",
       "22          25  0.980293  0.615399  current_layer  dsv2\n",
       "23          26  0.980104  0.619126  current_layer  dsv2\n",
       "24          27  0.980483  0.650771  current_layer  dsv2\n",
       "25          28  0.978209  0.647928  current_layer  dsv2\n",
       "0            3  0.460586  0.695427     next_layer  dsv2\n",
       "1            4  0.536887  0.707617     next_layer  dsv2\n",
       "2            5  0.581291  0.677994     next_layer  dsv2\n",
       "3            6  0.563100  0.646918     next_layer  dsv2\n",
       "4            7  0.571627  0.648939     next_layer  dsv2\n",
       "5            8  0.552678  0.634285     next_layer  dsv2\n",
       "6            9  0.552804  0.644328     next_layer  dsv2\n",
       "7           10  0.586281  0.636243     next_layer  dsv2\n",
       "8           11  0.549520  0.630874     next_layer  dsv2\n",
       "9           12  0.604346  0.669530     next_layer  dsv2\n",
       "10          13  0.538340  0.654434     next_layer  dsv2\n",
       "11          14  0.542698  0.659550     next_layer  dsv2\n",
       "12          15  0.520591  0.691195     next_layer  dsv2\n",
       "13          16  0.554636  0.705344     next_layer  dsv2\n",
       "14          17  0.561205  0.704712     next_layer  dsv2\n",
       "15          18  0.583818  0.729093     next_layer  dsv2\n",
       "16          19  0.518002  0.708060     next_layer  dsv2\n",
       "17          20  0.570237  0.730862     next_layer  dsv2\n",
       "18          21  0.541246  0.720945     next_layer  dsv2\n",
       "19          22  0.509348  0.728714     next_layer  dsv2\n",
       "20          23  0.547941  0.738252     next_layer  dsv2\n",
       "21          24  0.543962  0.728777     next_layer  dsv2\n",
       "22          25  0.550783  0.742357     next_layer  dsv2\n",
       "23          26  0.601756  0.764401     next_layer  dsv2\n",
       "24          27  0.624811  0.740273     next_layer  dsv2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "export_df = pd.concat([\n",
    "    pd.DataFrame(current_layer_accuracy).assign(target = 'current_layer'),\n",
    "    pd.DataFrame(next_layer_accuracy).assign(target = 'next_layer'),\n",
    "]).assign(model = model_prefix)\n",
    "display(export_df)\n",
    "\n",
    "export_df.to_csv(f'exports/transition-probe-{model_prefix}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [16:57<26:41, 400.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:50:51.915] [CUML] [warning] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 4/7 [24:58<21:37, 432.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 04:58:53.597] [CUML] [warning] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [34:03<15:45, 472.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 05:07:38.740] [CUML] [warning] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 6/7 [44:32<08:45, 525.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 05:18:26.971] [CUML] [warning] L-BFGS: max iterations reached\n",
      "[2025-05-12 05:18:26.984] [CUML] [warning] Maximum iterations reached before solver is converged. To increase model accuracy you can increase the number of iterations (max_iter) or improve the scaling of the input data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [52:26<00:00, 449.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 05:26:21.218] [CUML] [warning] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Predict TID\n",
    "\"\"\"\n",
    "tid_probe_accs = []\n",
    "\n",
    "for test_layer in tqdm(list(h_para_by_layer.keys())[::4]):\n",
    "\n",
    "    clear_all_cuda_memory(False)\n",
    "\n",
    "    top_tids =\\\n",
    "        sample_df\\\n",
    "        .pipe(lambda df: df[df['source'] == 'en'])\\\n",
    "        .groupby(['token_id', 'token'], as_index = False)\\\n",
    "        .agg(n = ('token', 'count')).sort_values(by = 'n', ascending = False)\\\n",
    "        .head(20_000)\n",
    "\n",
    "    valid_samples =\\\n",
    "        sample_df\\\n",
    "        .pipe(lambda df: df[df['token_id'].isin(top_tids['token_id'].tolist())])\n",
    "\n",
    "    y_df =\\\n",
    "        valid_samples\\\n",
    "        ['token_id']\\\n",
    "        .tolist()\n",
    "\n",
    "    y_cp = cupy.asarray(y_df)\n",
    "    x_cp_para = cupy.asarray(h_para_by_layer[test_layer][valid_samples['sample_ix'].tolist(), :].to(torch.float16).detach().cpu())\n",
    "    x_cp_orth = cupy.asarray(h_orth_by_layer[test_layer][valid_samples['sample_ix'].tolist(), :].to(torch.float16).detach().cpu())\n",
    "\n",
    "    tid_probe_accs.append({\n",
    "        'test_layer': test_layer + model_pre_mlp_layers + 1,\n",
    "        'para_acc': run_lr(x_cp_para, y_cp),\n",
    "        'orth_acc': run_lr(x_cp_orth, y_cp)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_layer</th>\n",
       "      <th>para_acc</th>\n",
       "      <th>orth_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.885774</td>\n",
       "      <td>0.938131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0.651347</td>\n",
       "      <td>0.859007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0.540993</td>\n",
       "      <td>0.805387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0.546801</td>\n",
       "      <td>0.795539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>0.655640</td>\n",
       "      <td>0.790909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23</td>\n",
       "      <td>0.556145</td>\n",
       "      <td>0.781650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27</td>\n",
       "      <td>0.532323</td>\n",
       "      <td>0.737205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_layer  para_acc  orth_acc\n",
       "0           3  0.885774  0.938131\n",
       "1           7  0.651347  0.859007\n",
       "2          11  0.540993  0.805387\n",
       "3          15  0.546801  0.795539\n",
       "4          19  0.655640  0.790909\n",
       "5          23  0.556145  0.781650\n",
       "6          27  0.532323  0.737205"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tid_export_df = pd.DataFrame(tid_probe_accs)\n",
    "display(tid_export_df)\n",
    "\n",
    "tid_export_df.to_csv(f'exports/transition-probe-tid-{model_prefix}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 3/13 [00:02<00:10,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 05:26:24.223] [CUML] [warning] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 4/13 [00:04<00:12,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 05:26:26.082] [CUML] [warning] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 5/13 [00:06<00:13,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 05:26:28.426] [CUML] [warning] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n",
      "[2025-05-12 05:26:29.082] [CUML] [warning] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 6/13 [00:09<00:14,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 05:26:31.211] [CUML] [warning] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 8/13 [00:15<00:11,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 05:26:36.515] [CUML] [warning] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n",
      "[2025-05-12 05:26:36.979] [CUML] [warning] L-BFGS line search failed (code 3); stopping at the last valid step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 10/13 [00:20<00:07,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 05:26:41.680] [CUML] [warning] L-BFGS: max iterations reached\n",
      "[2025-05-12 05:26:41.682] [CUML] [warning] Maximum iterations reached before solver is converged. To increase model accuracy you can increase the number of iterations (max_iter) or improve the scaling of the input data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 11/13 [00:22<00:04,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 05:26:44.182] [CUML] [warning] L-BFGS: max iterations reached\n",
      "[2025-05-12 05:26:44.183] [CUML] [warning] Maximum iterations reached before solver is converged. To increase model accuracy you can increase the number of iterations (max_iter) or improve the scaling of the input data.\n",
      "[2025-05-12 05:26:44.709] [CUML] [warning] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 12/13 [00:25<00:02,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 05:26:46.842] [CUML] [warning] L-BFGS: max iterations reached\n",
      "[2025-05-12 05:26:46.844] [CUML] [warning] Maximum iterations reached before solver is converged. To increase model accuracy you can increase the number of iterations (max_iter) or improve the scaling of the input data.\n",
      "[2025-05-12 05:26:47.425] [CUML] [warning] L-BFGS line search failed (code 3); stopping at the last valid step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:28<00:00,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-12 05:26:49.891] [CUML] [warning] L-BFGS stopped, because the line search failed to advance (step delta = 0.000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Predict Language\n",
    "\"\"\"\n",
    "lang_probe_accs = []\n",
    "\n",
    "for test_layer in tqdm(list(h_para_by_layer.keys())[::2]):\n",
    "\n",
    "    source_mapping = {source: i for i, source in enumerate(sample_df['source'].unique())}\n",
    "\n",
    "    y_df =\\\n",
    "        sample_df\\\n",
    "        .assign(source = lambda df: df['source'].map(source_mapping))\\\n",
    "        ['source']\\\n",
    "        .tolist()\n",
    "\n",
    "    y_cp = cupy.asarray(y_df)\n",
    "    x_cp_para = cupy.asarray(h_para_by_layer[test_layer].to(torch.float16).detach().cpu())\n",
    "    x_cp_orth = cupy.asarray(h_orth_by_layer[test_layer].to(torch.float16).detach().cpu())\n",
    "\n",
    "    lang_probe_accs.append({\n",
    "        'test_layer': test_layer + model_pre_mlp_layers + 1,\n",
    "        'para_acc': run_lr(x_cp_para, y_cp),\n",
    "        'orth_acc': run_lr(x_cp_orth, y_cp)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_layer</th>\n",
       "      <th>para_acc</th>\n",
       "      <th>orth_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.854535</td>\n",
       "      <td>0.989831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.796046</td>\n",
       "      <td>0.987873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0.747221</td>\n",
       "      <td>0.989641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.743052</td>\n",
       "      <td>0.991536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0.725240</td>\n",
       "      <td>0.991978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>0.749368</td>\n",
       "      <td>0.993178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>0.730483</td>\n",
       "      <td>0.991536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>0.790993</td>\n",
       "      <td>0.991473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19</td>\n",
       "      <td>0.796046</td>\n",
       "      <td>0.990904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>0.835965</td>\n",
       "      <td>0.991031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23</td>\n",
       "      <td>0.885232</td>\n",
       "      <td>0.994063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25</td>\n",
       "      <td>0.917446</td>\n",
       "      <td>0.994378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27</td>\n",
       "      <td>0.921741</td>\n",
       "      <td>0.995200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_layer  para_acc  orth_acc\n",
       "0            3  0.854535  0.989831\n",
       "1            5  0.796046  0.987873\n",
       "2            7  0.747221  0.989641\n",
       "3            9  0.743052  0.991536\n",
       "4           11  0.725240  0.991978\n",
       "5           13  0.749368  0.993178\n",
       "6           15  0.730483  0.991536\n",
       "7           17  0.790993  0.991473\n",
       "8           19  0.796046  0.990904\n",
       "9           21  0.835965  0.991031\n",
       "10          23  0.885232  0.994063\n",
       "11          25  0.917446  0.994378\n",
       "12          27  0.921741  0.995200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lang_export_df = pd.DataFrame(lang_probe_accs)\n",
    "display(lang_export_df)\n",
    "\n",
    "lang_export_df.to_csv(f'exports/transition-probe-lang-{model_prefix}.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
