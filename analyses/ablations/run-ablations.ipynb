{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ed3db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Runs ablation on MMLU subjects.\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d710dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers.loss.loss_utils import ForCausalLMLoss # Cross-entropy loss that handles label shifting\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from termcolor import colored\n",
    "import importlib\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from utils.memory import check_memory, clear_all_cuda_memory\n",
    "from utils.store_topk import convert_topk_to_df\n",
    "from utils.store_outputs import convert_outputs_to_df\n",
    "from utils import pretrained_models\n",
    "\n",
    "import pickle\n",
    "\n",
    "main_device = 'cuda:0'\n",
    "seed = 123\n",
    "clear_all_cuda_memory()\n",
    "check_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043893c1",
   "metadata": {},
   "source": [
    "## Load base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74be5209",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the base tokenizer/model\n",
    "\n",
    "Architectures supported currently:\n",
    "- OlMoE architecture, includes OLMoE-1B-7B-0125-Instruct (1B/7B)\n",
    "- Qwen2MoE architecture, inclues Qwen1.5-MoE-A2.7B-Chat (2.7B/14.3B), Qwen2-57B-A14B (14B/57B)\n",
    "- Deepseek v2 architecture, includes Deepseek-v2-Lite (2.4B/15.7B), Deepseek-v2 (21B/236B)\n",
    "- Deepseek v3 architecture, includes Deepseek-v3 (37B/671B), Deepseek-R1 (37B/671B), Moonlight-16B-A3B (3B/16B)\n",
    "- Qwen3MoE architecture, includes Qwen3-30B-A3B, Qwen3-235B-A22B\n",
    "\"\"\"\n",
    "selected_model_index = 4\n",
    "\n",
    "def get_model(index):\n",
    "    model = [\n",
    "        ('allenai/OLMoE-1B-7B-0125-Instruct', 'olmoe', 'olmoe'),\n",
    "        ('Qwen/Qwen1.5-MoE-A2.7B-Chat', 'qwen1.5moe', 'qwen2moe'),\n",
    "        ('deepseek-ai/DeepSeek-V2-Lite', 'dsv2', 'dsv2'),\n",
    "        ('moonshotai/Moonlight-16B-A3B', 'moonlight', 'dsv3'),\n",
    "        ('Qwen/Qwen3-30B-A3B', 'qwen3moe', 'qwen3moe')\n",
    "    ][index]\n",
    "\n",
    "    return model[0], model[1], model[2]\n",
    "\n",
    "model_id, model_prefix, model_architecture = get_model(selected_model_index)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token = False, add_bos_token = False, padding_side = 'left', trust_remote_code = True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype = torch.bfloat16, trust_remote_code = True).cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e974b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load reverse-engineered forward pass functions that return topk expert IDs and weights\n",
    "\"\"\"\n",
    "model_module = importlib.import_module(f\"utils.pretrained_models.{model_architecture}\")\n",
    "run_model_with_ablation = getattr(model_module, f\"run_{model_architecture}_with_ablation\")\n",
    "\n",
    "test_ablate_dict = {\n",
    "    1: {\n",
    "        (0, ): 0\n",
    "    }\n",
    "}\n",
    "\n",
    "def test_custom_forward_pass(model, pad_token_id):\n",
    "    inputs = tokenizer(['Hi! I am a dog and I like to bark', 'Vegetables are good for'], return_tensors = 'pt', padding = 'max_length', truncation = True, max_length = 512).to(model.device)\n",
    "    original_results = model(**inputs)\n",
    "    custom_results = run_model_with_ablation(model, inputs['input_ids'], inputs['attention_mask'], test_ablate_dict)\n",
    "    assert torch.equal(original_results.logits, custom_results['logits']), 'Error in custom forward'\n",
    "    assert len(custom_results['all_topk_experts']) == len(custom_results['all_topk_weights']), 'Length of topk IDs and weights not equal'\n",
    "    print(f\"Length of topk: {len(custom_results['all_topk_experts'])}\")\n",
    "    print(f\"Topk size: {custom_results['all_topk_experts'][0].shape}\")\n",
    "    print(f\"First token topk IDs: {custom_results['all_topk_experts'][0][1,]}\")\n",
    "    print(f\"First token topk weights: {custom_results['all_topk_weights'][0][1,]}\")\n",
    "    loss = ForCausalLMLoss(custom_results['logits'], torch.where(inputs['input_ids'] == pad_token_id, torch.tensor(-100), inputs['input_ids']), model.config.vocab_size).detach().cpu().item()\n",
    "    print(f\"LM loss: {loss}\")\n",
    "\n",
    "test_custom_forward_pass(model, tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40d8f4e",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3afab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(f'{model_prefix}-samples.csv')\n",
    "topk_df = pd.read_csv(f'{model_prefix}-topks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094e715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df\\\n",
    "    .groupby(['q_ix', 'lang_ix', 'domain_ix', 'source_id', 'domain', 'question_output_token', 'answer_char'], as_index = False)\\\n",
    "    .agg(n_tokens = ('q_ix', 'count'))\\\n",
    "    .assign(is_correct = lambda df: np.where(df['question_output_token'].str.strip() == df['answer_char'], 1, 0))\\\n",
    "    .groupby('domain', as_index = False)\\\n",
    "    .agg(n_accurate = ('is_correct', 'sum'), n_total = ('q_ix', 'count'))\\\n",
    "    .assign(accuracy = lambda df: df['n_accurate']/df['n_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ccffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df\\\n",
    "    [['q_ix', 'domain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7007e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_df\\\n",
    "    .pipe(lambda df: df[df['topk_ix'] == 1])\\\n",
    "    .drop_duplicates('expert')\\\n",
    "    .sort_values('expert')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
