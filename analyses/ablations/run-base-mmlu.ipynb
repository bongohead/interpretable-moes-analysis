{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea0f6489",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Runs ablation on MMLU subjects.\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "639d9a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CUDA memory cleared on all devices.\n",
      "Device 0: NVIDIA H100 PCIe\n",
      "  Allocated: 0.00 GB\n",
      "  Reserved: 0.00 GB\n",
      "  Total: 79.10 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers.loss.loss_utils import ForCausalLMLoss # Cross-entropy loss that handles label shifting\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from termcolor import colored\n",
    "import importlib\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from utils.memory import check_memory, clear_all_cuda_memory\n",
    "from utils.store_topk import convert_topk_to_df\n",
    "from utils.store_outputs import convert_outputs_to_df\n",
    "from utils import pretrained_models\n",
    "\n",
    "import pickle\n",
    "\n",
    "main_device = 'cuda:0'\n",
    "seed = 123\n",
    "clear_all_cuda_memory()\n",
    "check_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519d22c6",
   "metadata": {},
   "source": [
    "## Load base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8da4a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c16393287b9452788b751a4b8fe576d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load the base tokenizer/model\n",
    "\n",
    "Architectures supported currently:\n",
    "- OlMoE architecture, includes OLMoE-1B-7B-0125-Instruct (1B/7B)\n",
    "- Qwen2MoE architecture, inclues Qwen1.5-MoE-A2.7B-Chat (2.7B/14.3B), Qwen2-57B-A14B (14B/57B)\n",
    "- Deepseek v2 architecture, includes Deepseek-v2-Lite (2.4B/15.7B), Deepseek-v2 (21B/236B)\n",
    "- Deepseek v3 architecture, includes Deepseek-v3 (37B/671B), Deepseek-R1 (37B/671B), Moonlight-16B-A3B (3B/16B)\n",
    "- Qwen3MoE architecture, includes Qwen3-30B-A3B, Qwen3-235B-A22B\n",
    "\"\"\"\n",
    "selected_model_index = 4\n",
    "\n",
    "def get_model(index):\n",
    "    model = [\n",
    "        ('allenai/OLMoE-1B-7B-0125-Instruct', 'olmoe', 'olmoe'),\n",
    "        ('Qwen/Qwen1.5-MoE-A2.7B-Chat', 'qwen1.5moe', 'qwen2moe'),\n",
    "        ('deepseek-ai/DeepSeek-V2-Lite', 'dsv2', 'dsv2'),\n",
    "        ('moonshotai/Moonlight-16B-A3B', 'moonlight', 'dsv3'),\n",
    "        ('Qwen/Qwen3-30B-A3B', 'qwen3moe', 'qwen3moe')\n",
    "    ][index]\n",
    "\n",
    "    return model[0], model[1], model[2]\n",
    "\n",
    "model_id, model_prefix, model_architecture = get_model(selected_model_index)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token = False, add_bos_token = False, padding_side = 'left', trust_remote_code = True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype = torch.bfloat16, trust_remote_code = True).cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8f685d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of topk: 48\n",
      "Topk size: torch.Size([1024, 8])\n",
      "First token topk IDs: tensor([ 84,  53,   1, 119,  68, 114,  16,  31])\n",
      "First token topk weights: tensor([0.2197, 0.1924, 0.1465, 0.1357, 0.0820, 0.0796, 0.0762, 0.0679])\n",
      "LM loss: 3.733102798461914\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load reverse-engineered forward pass functions that return topk expert IDs and weights\n",
    "\"\"\"\n",
    "model_module = importlib.import_module(f\"utils.pretrained_models.{model_architecture}\")\n",
    "run_model_return_topk = getattr(model_module, f\"run_{model_architecture}_return_topk\")\n",
    "\n",
    "def test_custom_forward_pass(model, pad_token_id):\n",
    "    inputs = tokenizer(['Hi! I am a dog and I like to bark', 'Vegetables are good for'], return_tensors = 'pt', padding = 'max_length', truncation = True, max_length = 512).to(model.device)\n",
    "    original_results = model(**inputs)\n",
    "    custom_results = run_model_return_topk(model, inputs['input_ids'], inputs['attention_mask'], return_hidden_states = False)\n",
    "    assert torch.equal(original_results.logits, custom_results['logits']), 'Error in custom forward'\n",
    "    assert len(custom_results['all_topk_experts']) == len(custom_results['all_topk_weights']), 'Length of topk IDs and weights not equal'\n",
    "    print(f\"Length of topk: {len(custom_results['all_topk_experts'])}\")\n",
    "    print(f\"Topk size: {custom_results['all_topk_experts'][0].shape}\")\n",
    "    print(f\"First token topk IDs: {custom_results['all_topk_experts'][0][1,]}\")\n",
    "    print(f\"First token topk weights: {custom_results['all_topk_weights'][0][1,]}\")\n",
    "    loss = ForCausalLMLoss(custom_results['logits'], torch.where(inputs['input_ids'] == pad_token_id, torch.tensor(-100), inputs['input_ids']), model.config.vocab_size).detach().cpu().item()\n",
    "    print(f\"LM loss: {loss}\")\n",
    "\n",
    "test_custom_forward_pass(model, tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953cd66f",
   "metadata": {},
   "source": [
    "## Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4773ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract_algebra</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anatomy</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>astronomy</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business_ethics</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clinical_knowledge</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>college_biology</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>college_chemistry</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>college_computer_science</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>college_mathematics</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>college_medicine</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>college_physics</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>computer_security</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>conceptual_physics</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>econometrics</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>electrical_engineering</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>elementary_mathematics</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>formal_logic</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>global_facts</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>high_school_biology</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>high_school_chemistry</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>high_school_computer_science</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>high_school_european_history</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>high_school_geography</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>high_school_government_and_politics</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>high_school_macroeconomics</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>high_school_mathematics</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>high_school_microeconomics</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>high_school_physics</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>high_school_psychology</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>high_school_statistics</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>high_school_us_history</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>high_school_world_history</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>human_aging</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>human_sexuality</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>international_law</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>jurisprudence</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>logical_fallacies</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>machine_learning</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>management</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>marketing</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>medical_genetics</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>moral_disputes</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>moral_scenarios</td>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>nutrition</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>philosophy</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>prehistory</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>professional_accounting</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>professional_law</td>\n",
       "      <td>1534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>professional_medicine</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>professional_psychology</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>public_relations</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>security_studies</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>sociology</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>us_foreign_policy</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>virology</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>world_religions</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                subject  count\n",
       "0                      abstract_algebra    100\n",
       "1                               anatomy    135\n",
       "2                             astronomy    152\n",
       "3                       business_ethics    100\n",
       "4                    clinical_knowledge    265\n",
       "5                       college_biology    144\n",
       "6                     college_chemistry    100\n",
       "7              college_computer_science    100\n",
       "8                   college_mathematics    100\n",
       "9                      college_medicine    173\n",
       "10                      college_physics    102\n",
       "11                    computer_security    100\n",
       "12                   conceptual_physics    235\n",
       "13                         econometrics    114\n",
       "14               electrical_engineering    145\n",
       "15               elementary_mathematics    378\n",
       "16                         formal_logic    126\n",
       "17                         global_facts    100\n",
       "18                  high_school_biology    310\n",
       "19                high_school_chemistry    203\n",
       "20         high_school_computer_science    100\n",
       "21         high_school_european_history    165\n",
       "22                high_school_geography    198\n",
       "23  high_school_government_and_politics    193\n",
       "24           high_school_macroeconomics    390\n",
       "25              high_school_mathematics    270\n",
       "26           high_school_microeconomics    238\n",
       "27                  high_school_physics    151\n",
       "28               high_school_psychology    545\n",
       "29               high_school_statistics    216\n",
       "30               high_school_us_history    204\n",
       "31            high_school_world_history    237\n",
       "32                          human_aging    223\n",
       "33                      human_sexuality    131\n",
       "34                    international_law    121\n",
       "35                        jurisprudence    108\n",
       "36                    logical_fallacies    163\n",
       "37                     machine_learning    112\n",
       "38                           management    103\n",
       "39                            marketing    234\n",
       "40                     medical_genetics    100\n",
       "41                        miscellaneous    783\n",
       "42                       moral_disputes    346\n",
       "43                      moral_scenarios    895\n",
       "44                            nutrition    306\n",
       "45                           philosophy    311\n",
       "46                           prehistory    324\n",
       "47              professional_accounting    282\n",
       "48                     professional_law   1534\n",
       "49                professional_medicine    272\n",
       "50              professional_psychology    612\n",
       "51                     public_relations    110\n",
       "52                     security_studies    245\n",
       "53                            sociology    201\n",
       "54                    us_foreign_policy    100\n",
       "55                             virology    166\n",
       "56                      world_religions    171"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "Get MMLU data and domains to test\n",
    "\"\"\"\n",
    "mmlu_ds = {\n",
    "    lang: load_dataset(\"CohereLabs/Global-MMLU\", lang, split = 'test')\n",
    "    for lang in ['en']\n",
    "}\n",
    "\n",
    "display(pd.DataFrame(mmlu_ds['en']).groupby('subject', as_index = False).agg(count = ('sample_id', 'count')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9752398a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_ix</th>\n",
       "      <th>domain_ix</th>\n",
       "      <th>source_id</th>\n",
       "      <th>stem</th>\n",
       "      <th>choices</th>\n",
       "      <th>domain</th>\n",
       "      <th>answer_char</th>\n",
       "      <th>lang</th>\n",
       "      <th>q_ix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>college_computer_science/test/0</td>\n",
       "      <td>The access matrix approach to protection has t...</td>\n",
       "      <td>[the matrix, if stored directly, is large and ...</td>\n",
       "      <td>compsci</td>\n",
       "      <td>A</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>college_computer_science/test/1</td>\n",
       "      <td>An integer c is a common divisor of two intege...</td>\n",
       "      <td>[{-6,-2, -1, 1, 2, 6}, {-6, -2, -1, 0, 1, 2, 6...</td>\n",
       "      <td>compsci</td>\n",
       "      <td>C</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>college_computer_science/test/2</td>\n",
       "      <td>In the NoNicks operating system, the time requ...</td>\n",
       "      <td>[1:4, 1:3.5, 1:1, 1.1:1]</td>\n",
       "      <td>compsci</td>\n",
       "      <td>B</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>college_computer_science/test/3</td>\n",
       "      <td>You want to cluster 7 points into 3 clusters u...</td>\n",
       "      <td>[C1: (3,3), C2: (4,4), C3: (6,6), C1: (3,3), C...</td>\n",
       "      <td>compsci</td>\n",
       "      <td>A</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>college_computer_science/test/4</td>\n",
       "      <td>Any set of Boolean operators that is sufficien...</td>\n",
       "      <td>[{AND, NOT}, {NOT, OR}, {AND, OR}, {NAND}]</td>\n",
       "      <td>compsci</td>\n",
       "      <td>C</td>\n",
       "      <td>en</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>795</td>\n",
       "      <td>195</td>\n",
       "      <td>high_school_computer_science/test/95</td>\n",
       "      <td>Consider the following code segment, which use...</td>\n",
       "      <td>[1 1, 1 2, 2 3, 3 2]</td>\n",
       "      <td>compsci</td>\n",
       "      <td>C</td>\n",
       "      <td>en</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>796</td>\n",
       "      <td>196</td>\n",
       "      <td>high_school_computer_science/test/96</td>\n",
       "      <td>A digital photo file contains data representin...</td>\n",
       "      <td>[Determining the likelihood that the photo is ...</td>\n",
       "      <td>compsci</td>\n",
       "      <td>B</td>\n",
       "      <td>en</td>\n",
       "      <td>796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>797</td>\n",
       "      <td>197</td>\n",
       "      <td>high_school_computer_science/test/97</td>\n",
       "      <td>In Python 3, what is ['a', 'Chemistry', 0, 1][...</td>\n",
       "      <td>[a, Chemistry, 0, 1]</td>\n",
       "      <td>compsci</td>\n",
       "      <td>B</td>\n",
       "      <td>en</td>\n",
       "      <td>797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>798</td>\n",
       "      <td>198</td>\n",
       "      <td>high_school_computer_science/test/98</td>\n",
       "      <td>Two computers are built by different manufactu...</td>\n",
       "      <td>[The computers cannot communicate because diff...</td>\n",
       "      <td>compsci</td>\n",
       "      <td>D</td>\n",
       "      <td>en</td>\n",
       "      <td>798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>799</td>\n",
       "      <td>199</td>\n",
       "      <td>high_school_computer_science/test/99</td>\n",
       "      <td>Which of the following activities poses the gr...</td>\n",
       "      <td>[Making a purchase at an online store that use...</td>\n",
       "      <td>compsci</td>\n",
       "      <td>C</td>\n",
       "      <td>en</td>\n",
       "      <td>799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     lang_ix  domain_ix                             source_id  \\\n",
       "0          0          0       college_computer_science/test/0   \n",
       "1          1          1       college_computer_science/test/1   \n",
       "2          2          2       college_computer_science/test/2   \n",
       "3          3          3       college_computer_science/test/3   \n",
       "4          4          4       college_computer_science/test/4   \n",
       "..       ...        ...                                   ...   \n",
       "795      795        195  high_school_computer_science/test/95   \n",
       "796      796        196  high_school_computer_science/test/96   \n",
       "797      797        197  high_school_computer_science/test/97   \n",
       "798      798        198  high_school_computer_science/test/98   \n",
       "799      799        199  high_school_computer_science/test/99   \n",
       "\n",
       "                                                  stem  \\\n",
       "0    The access matrix approach to protection has t...   \n",
       "1    An integer c is a common divisor of two intege...   \n",
       "2    In the NoNicks operating system, the time requ...   \n",
       "3    You want to cluster 7 points into 3 clusters u...   \n",
       "4    Any set of Boolean operators that is sufficien...   \n",
       "..                                                 ...   \n",
       "795  Consider the following code segment, which use...   \n",
       "796  A digital photo file contains data representin...   \n",
       "797  In Python 3, what is ['a', 'Chemistry', 0, 1][...   \n",
       "798  Two computers are built by different manufactu...   \n",
       "799  Which of the following activities poses the gr...   \n",
       "\n",
       "                                               choices   domain answer_char  \\\n",
       "0    [the matrix, if stored directly, is large and ...  compsci           A   \n",
       "1    [{-6,-2, -1, 1, 2, 6}, {-6, -2, -1, 0, 1, 2, 6...  compsci           C   \n",
       "2                             [1:4, 1:3.5, 1:1, 1.1:1]  compsci           B   \n",
       "3    [C1: (3,3), C2: (4,4), C3: (6,6), C1: (3,3), C...  compsci           A   \n",
       "4           [{AND, NOT}, {NOT, OR}, {AND, OR}, {NAND}]  compsci           C   \n",
       "..                                                 ...      ...         ...   \n",
       "795                               [1 1, 1 2, 2 3, 3 2]  compsci           C   \n",
       "796  [Determining the likelihood that the photo is ...  compsci           B   \n",
       "797                               [a, Chemistry, 0, 1]  compsci           B   \n",
       "798  [The computers cannot communicate because diff...  compsci           D   \n",
       "799  [Making a purchase at an online store that use...  compsci           C   \n",
       "\n",
       "    lang  q_ix  \n",
       "0     en     0  \n",
       "1     en     1  \n",
       "2     en     2  \n",
       "3     en     3  \n",
       "4     en     4  \n",
       "..   ...   ...  \n",
       "795   en   795  \n",
       "796   en   796  \n",
       "797   en   797  \n",
       "798   en   798  \n",
       "799   en   799  \n",
       "\n",
       "[800 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dict containing {final_domains: [source1, source2], ...}\n",
    "mmlu_domain_mappings = {\n",
    "    'math': ['elementary_mathematics'], \n",
    "    # 'statistics': ['high_school_statistics'],\n",
    "    'compsci': ['high_school_computer_science', 'college_computer_science'],\n",
    "    'chemistry': ['high_school_chemistry'],\n",
    "    'biology': ['high_school_biology']\n",
    "}\n",
    "\n",
    "def get_mmlu_df(raw_ds, domain_map, max_questions_per_domain):\n",
    "    \"\"\"\n",
    "    Clean + prep MMLU dataset\n",
    "    \"\"\"\n",
    "    source_to_domain_map = {source: domain for domain, sources in domain_map.items() for source in sources} # Map each source => domain\n",
    "    final_ds = []\n",
    "    lang_ix = 0\n",
    "    for q in raw_ds:\n",
    "        if q['subject'] not in source_to_domain_map.keys():\n",
    "            continue\n",
    "        domain_count = len([x for x in final_ds if x['domain'] == source_to_domain_map[q['subject']]])\n",
    "        if domain_count >= max_questions_per_domain:\n",
    "            continue\n",
    "        final_ds.append({\n",
    "            'lang_ix': lang_ix,\n",
    "            'domain_ix': domain_count,\n",
    "            'source_id': q['sample_id'],\n",
    "            'stem': q['question'],\n",
    "            'choices': [q['option_a'], q['option_b'], q['option_c'], q['option_d']],\n",
    "            'domain': source_to_domain_map[q['subject']],\n",
    "            'answer_char': q['answer']\n",
    "        })\n",
    "        lang_ix += 1\n",
    "\n",
    "    return pd.DataFrame(final_ds)\n",
    "\n",
    "mmlu_raw_dfs_by_lang = {\n",
    "    lang: get_mmlu_df(ds, mmlu_domain_mappings, 200).assign(lang = lang)\n",
    "    for lang, ds in mmlu_ds.items()\n",
    "}\n",
    "\n",
    "# assert all(mmlu_raw_dfs_by_lang['en']['source_id'] == mmlu_raw_dfs_by_lang['es']['source_id'])\n",
    "# assert all(mmlu_raw_dfs_by_lang['en']['source_id'] == mmlu_raw_dfs_by_lang['zh']['source_id'])\n",
    "\n",
    "mmlu_raw_df = pd.concat([df for _, df in mmlu_raw_dfs_by_lang.items()]).pipe(lambda df: df.assign(q_ix = list(range(0, len(df)))))\n",
    "mmlu_raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "671b61cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_ix</th>\n",
       "      <th>domain_ix</th>\n",
       "      <th>source_id</th>\n",
       "      <th>stem</th>\n",
       "      <th>choices</th>\n",
       "      <th>domain</th>\n",
       "      <th>answer_char</th>\n",
       "      <th>lang</th>\n",
       "      <th>q_ix</th>\n",
       "      <th>input_prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>college_computer_science/test/0</td>\n",
       "      <td>The access matrix approach to protection has t...</td>\n",
       "      <td>[the matrix, if stored directly, is large and ...</td>\n",
       "      <td>compsci</td>\n",
       "      <td>A</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou will be provided with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>college_computer_science/test/1</td>\n",
       "      <td>An integer c is a common divisor of two intege...</td>\n",
       "      <td>[{-6,-2, -1, 1, 2, 6}, {-6, -2, -1, 0, 1, 2, 6...</td>\n",
       "      <td>compsci</td>\n",
       "      <td>C</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou will be provided with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>college_computer_science/test/2</td>\n",
       "      <td>In the NoNicks operating system, the time requ...</td>\n",
       "      <td>[1:4, 1:3.5, 1:1, 1.1:1]</td>\n",
       "      <td>compsci</td>\n",
       "      <td>B</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou will be provided with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>college_computer_science/test/3</td>\n",
       "      <td>You want to cluster 7 points into 3 clusters u...</td>\n",
       "      <td>[C1: (3,3), C2: (4,4), C3: (6,6), C1: (3,3), C...</td>\n",
       "      <td>compsci</td>\n",
       "      <td>A</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou will be provided with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>college_computer_science/test/4</td>\n",
       "      <td>Any set of Boolean operators that is sufficien...</td>\n",
       "      <td>[{AND, NOT}, {NOT, OR}, {AND, OR}, {NAND}]</td>\n",
       "      <td>compsci</td>\n",
       "      <td>C</td>\n",
       "      <td>en</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou will be provided with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>795</td>\n",
       "      <td>195</td>\n",
       "      <td>high_school_computer_science/test/95</td>\n",
       "      <td>Consider the following code segment, which use...</td>\n",
       "      <td>[1 1, 1 2, 2 3, 3 2]</td>\n",
       "      <td>compsci</td>\n",
       "      <td>C</td>\n",
       "      <td>en</td>\n",
       "      <td>795</td>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou will be provided with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>796</td>\n",
       "      <td>196</td>\n",
       "      <td>high_school_computer_science/test/96</td>\n",
       "      <td>A digital photo file contains data representin...</td>\n",
       "      <td>[Determining the likelihood that the photo is ...</td>\n",
       "      <td>compsci</td>\n",
       "      <td>B</td>\n",
       "      <td>en</td>\n",
       "      <td>796</td>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou will be provided with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>797</td>\n",
       "      <td>197</td>\n",
       "      <td>high_school_computer_science/test/97</td>\n",
       "      <td>In Python 3, what is ['a', 'Chemistry', 0, 1][...</td>\n",
       "      <td>[a, Chemistry, 0, 1]</td>\n",
       "      <td>compsci</td>\n",
       "      <td>B</td>\n",
       "      <td>en</td>\n",
       "      <td>797</td>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou will be provided with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>798</td>\n",
       "      <td>198</td>\n",
       "      <td>high_school_computer_science/test/98</td>\n",
       "      <td>Two computers are built by different manufactu...</td>\n",
       "      <td>[The computers cannot communicate because diff...</td>\n",
       "      <td>compsci</td>\n",
       "      <td>D</td>\n",
       "      <td>en</td>\n",
       "      <td>798</td>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou will be provided with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>799</td>\n",
       "      <td>199</td>\n",
       "      <td>high_school_computer_science/test/99</td>\n",
       "      <td>Which of the following activities poses the gr...</td>\n",
       "      <td>[Making a purchase at an online store that use...</td>\n",
       "      <td>compsci</td>\n",
       "      <td>C</td>\n",
       "      <td>en</td>\n",
       "      <td>799</td>\n",
       "      <td>&lt;|im_start|&gt;system\\nYou will be provided with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     lang_ix  domain_ix                             source_id  \\\n",
       "0          0          0       college_computer_science/test/0   \n",
       "1          1          1       college_computer_science/test/1   \n",
       "2          2          2       college_computer_science/test/2   \n",
       "3          3          3       college_computer_science/test/3   \n",
       "4          4          4       college_computer_science/test/4   \n",
       "..       ...        ...                                   ...   \n",
       "795      795        195  high_school_computer_science/test/95   \n",
       "796      796        196  high_school_computer_science/test/96   \n",
       "797      797        197  high_school_computer_science/test/97   \n",
       "798      798        198  high_school_computer_science/test/98   \n",
       "799      799        199  high_school_computer_science/test/99   \n",
       "\n",
       "                                                  stem  \\\n",
       "0    The access matrix approach to protection has t...   \n",
       "1    An integer c is a common divisor of two intege...   \n",
       "2    In the NoNicks operating system, the time requ...   \n",
       "3    You want to cluster 7 points into 3 clusters u...   \n",
       "4    Any set of Boolean operators that is sufficien...   \n",
       "..                                                 ...   \n",
       "795  Consider the following code segment, which use...   \n",
       "796  A digital photo file contains data representin...   \n",
       "797  In Python 3, what is ['a', 'Chemistry', 0, 1][...   \n",
       "798  Two computers are built by different manufactu...   \n",
       "799  Which of the following activities poses the gr...   \n",
       "\n",
       "                                               choices   domain answer_char  \\\n",
       "0    [the matrix, if stored directly, is large and ...  compsci           A   \n",
       "1    [{-6,-2, -1, 1, 2, 6}, {-6, -2, -1, 0, 1, 2, 6...  compsci           C   \n",
       "2                             [1:4, 1:3.5, 1:1, 1.1:1]  compsci           B   \n",
       "3    [C1: (3,3), C2: (4,4), C3: (6,6), C1: (3,3), C...  compsci           A   \n",
       "4           [{AND, NOT}, {NOT, OR}, {AND, OR}, {NAND}]  compsci           C   \n",
       "..                                                 ...      ...         ...   \n",
       "795                               [1 1, 1 2, 2 3, 3 2]  compsci           C   \n",
       "796  [Determining the likelihood that the photo is ...  compsci           B   \n",
       "797                               [a, Chemistry, 0, 1]  compsci           B   \n",
       "798  [The computers cannot communicate because diff...  compsci           D   \n",
       "799  [Making a purchase at an online store that use...  compsci           C   \n",
       "\n",
       "    lang  q_ix                                       input_prompt  \n",
       "0     en     0  <|im_start|>system\\nYou will be provided with ...  \n",
       "1     en     1  <|im_start|>system\\nYou will be provided with ...  \n",
       "2     en     2  <|im_start|>system\\nYou will be provided with ...  \n",
       "3     en     3  <|im_start|>system\\nYou will be provided with ...  \n",
       "4     en     4  <|im_start|>system\\nYou will be provided with ...  \n",
       "..   ...   ...                                                ...  \n",
       "795   en   795  <|im_start|>system\\nYou will be provided with ...  \n",
       "796   en   796  <|im_start|>system\\nYou will be provided with ...  \n",
       "797   en   797  <|im_start|>system\\nYou will be provided with ...  \n",
       "798   en   798  <|im_start|>system\\nYou will be provided with ...  \n",
       "799   en   799  <|im_start|>system\\nYou will be provided with ...  \n",
       "\n",
       "[800 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You will be provided with a multiple-choice question, as well as a list of possible answer choices. Respond exactly with: \"The correct answer is {X}\", substituting in X with the code for the correct choice.<|im_end|>\n",
      "<|im_start|>user\n",
      "Question: A lesion causing compression of the facial nerve at the stylomastoid foramen will cause ipsilateral\n",
      "Choices:\n",
      "(A) paralysis of the facial muscles.\n",
      "(B) paralysis of the facial muscles and loss of taste.\n",
      "(C) paralysis of the facial muscles, loss of taste and lacrimation.\n",
      "(D) paralysis of the facial muscles, loss of taste, lacrimation and decreased salivation.\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "The correct answer is A<|im_end|>\n",
      "<|im_start|>user\n",
      "Question: The access matrix approach to protection has the difficulty that\n",
      "Choices:\n",
      "(A) the matrix, if stored directly, is large and can be clumsy to manage\n",
      "(B) it is not capable of expressing complex protection requirements\n",
      "(C) deciding whether a process has access to a resource is undecidable\n",
      "(D) there is no way to express who has rights to change the access matrix itself\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "The correct answer is\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create function to map MMLU data into an instruct-formatted string\n",
    "\"\"\"\n",
    "append_think = '\\n<think>\\n\\n</think>\\n\\n' if model_prefix == 'qwen3moe' else ''\n",
    "\n",
    "def prep_question(question, choices):\n",
    "    prompt = f\"Question: {question}\\nChoices:\\n\"\n",
    "    for i, option in enumerate(choices):\n",
    "        letter = chr(65 + i)\n",
    "        prompt += f\"({letter}) {option}\\n\"\n",
    "    return prompt\n",
    "\n",
    "fs_ex = [\n",
    "    [q for q in mmlu_ds['en'] if q['subject'] == 'anatomy'][0]\n",
    "]\n",
    "\n",
    "base_prompt = [\n",
    "    {'role': 'system', 'content': 'You will be provided with a multiple-choice question, as well as a list of possible answer choices. Respond exactly with: \"The correct answer is {X}\", substituting in X with the code for the correct choice.'},\n",
    "    {'role': 'user', 'content': prep_question(fs_ex[0]['question'], [fs_ex[0]['option_a'], fs_ex[0]['option_b'], fs_ex[0]['option_c'], fs_ex[0]['option_d']])},\n",
    "    {'role': 'assistant', 'content': 'The correct answer is ' + fs_ex[0]['answer']}\n",
    "]\n",
    "\n",
    "mmlu_df = \\\n",
    "    mmlu_raw_df\\\n",
    "    .assign(\n",
    "        input_prompt = lambda df: df.apply(\n",
    "            lambda q: tokenizer.apply_chat_template(\n",
    "                base_prompt + [{'role': 'user', 'content': prep_question(q['stem'], q['choices'])}, {'role': 'assistant', 'content': f'{append_think}The correct answer is'}],\n",
    "                tokenize = False,\n",
    "                add_generation_prompt = False,\n",
    "                continue_final_message = True # Otherwise appends eos token\n",
    "            ), \n",
    "            axis = 1\n",
    "        )\n",
    "    )\n",
    "\n",
    "display(mmlu_df)\n",
    "print(mmlu_df['input_prompt'].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "129da91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(554)\n",
      "{'q_indices': tensor([0, 1, 2, 3]), 'lang_indices': tensor([0, 1, 2, 3]), 'domain_indices': tensor([0, 1, 2, 3]), 'domains': ['compsci', 'compsci', 'compsci', 'compsci'], 'stems': ['The access matrix approach to protection has the difficulty that', 'An integer c is a common divisor of two integers x and y if and only if c is a divisor of x and c is a divisor of y. Which of the following sets of integers could possibly be the set of all common divisors of two integers?', 'In the NoNicks operating system, the time required by a single file-read operation has four nonoverlapping components:\\ndisk seek time-25 msec\\ndisk latency time-8 msec\\ndisk transfer time- 1 msec per 1,000 bytes\\noperating system overhead-1 msec per 1,000 bytes + 10 msec\\nIn version 1 of the system, the file read retrieved blocks of 1,000 bytes. In version 2, the file read (along with the underlying layout on disk) was modified to retrieve blocks of 4,000 bytes. The ratio of-the time required to read a large file under version 2 to the time required to read the same large file under version 1 is approximately', 'You want to cluster 7 points into 3 clusters using the k-Means Clustering algorithm. Suppose after the first iteration, clusters C1, C2 and C3 contain the following two-dimensional points: C1 contains the 2 points: {(0,6), (6,0)} C2 contains the 3 points: {(2,2), (4,4), (6,6)} C3 contains the 2 points: {(5,5), (7,7)} What are the cluster centers computed for these 3 clusters?'], 'choices': [('the matrix, if stored directly, is large and can be clumsy to manage', '{-6,-2, -1, 1, 2, 6}', '1:4', 'C1: (3,3), C2: (4,4), C3: (6,6)'), ('it is not capable of expressing complex protection requirements', '{-6, -2, -1, 0, 1, 2, 6}', '1:3.5', 'C1: (3,3), C2: (6,6), C3: (12,12)'), ('deciding whether a process has access to a resource is undecidable', '{-6, -3, -2, -1, 1, 2, 3, 6}', '1:1', 'C1: (6,6), C2: (12,12), C3: (12,12)'), ('there is no way to express who has rights to change the access matrix itself', '{-6, -3, -2, -1, 0, 1, 2, 3, 6}', '1.1:1', 'C1: (0,0), C2: (48,48), C3: (35,35)')], 'answer_chars': ['A', 'C', 'B', 'A'], 'input_ids': tensor([[151643, 151643, 151643,  ...,   4396,   4226,    374],\n",
      "        [151643, 151643, 151643,  ...,   4396,   4226,    374],\n",
      "        [151643, 151643, 151643,  ...,   4396,   4226,    374],\n",
      "        [151643, 151643, 151643,  ...,   4396,   4226,    374]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        [0, 0, 0,  ..., 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Load dataset into a dataloader\n",
    "\"\"\"\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, q_indices, lang_indices, domain_indices, domains, stems, choices, answer_chars, tokenized_prompts):\n",
    "        self.q_indices = q_indices\n",
    "        self.lang_indices = lang_indices\n",
    "        self.domain_indices = domain_indices\n",
    "        self.domains = domains\n",
    "        self.stems = stems\n",
    "        self.choices = choices\n",
    "        self.answer_chars = answer_chars\n",
    "        self.input_ids = tokenized_prompts['input_ids']\n",
    "        self.attention_mask = tokenized_prompts['attention_mask']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'q_indices': self.q_indices[idx],\n",
    "            'lang_indices': self.lang_indices[idx],\n",
    "            'domain_indices': self.domain_indices[idx],\n",
    "            'domains': self.domains[idx],\n",
    "            'stems': self.stems[idx],\n",
    "            'choices': self.choices[idx],\n",
    "            'answer_chars': self.answer_chars[idx],\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'attention_mask': self.attention_mask[idx]\n",
    "        }\n",
    "\n",
    "tokenized_prompts = tokenizer(mmlu_df['input_prompt'].tolist(), add_special_tokens = False, max_length = 1024, padding = 'max_length', truncation = True, return_tensors = 'pt')\n",
    "print(tokenized_prompts['attention_mask'].sum(dim = 1).max()) # Must be under max length to confirm nothing was truncated\n",
    "\n",
    "mmlu_dl = DataLoader(TextDataset(\n",
    "    mmlu_df['q_ix'].tolist(),\n",
    "    mmlu_df['lang_ix'].tolist(),\n",
    "    mmlu_df['domain_ix'].tolist(),\n",
    "    mmlu_df['domain'].tolist(),\n",
    "    mmlu_df['stem'].tolist(),\n",
    "    mmlu_df['choices'].tolist(),\n",
    "    mmlu_df['answer_char'].tolist(),\n",
    "    tokenized_prompts\n",
    "), batch_size = 4, shuffle = False)\n",
    "\n",
    "print(next(iter(mmlu_dl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9699684a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(554)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Load dataset into a dataloader. The dataloader returns the original tokens - this is important for BPE tokenizers as otherwise it's difficult to reconstruct the correct string later!\n",
    "\"\"\"\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ReconstructableTextDataset(Dataset):\n",
    "\n",
    "    def __init__(self, raw_texts, q_indices, tokenizer, max_length):\n",
    "        \"\"\"\n",
    "        Creates a dataset object that also returns a B x N list of the original tokens in the same position as the input ids.\n",
    "\n",
    "        Params:\n",
    "            @raw_texts: A list of samples of text dataset.\n",
    "            @q_indices: A list of question indices attached to the raw texts.\n",
    "            @tokenizer: A HF tokenizer object.\n",
    "        \"\"\"\n",
    "        tokenized = tokenizer(raw_texts, add_special_tokens = False, max_length = max_length, padding = 'max_length', truncation = True, return_offsets_mapping = True, return_tensors = 'pt')\n",
    "\n",
    "        self.input_ids = tokenized['input_ids']\n",
    "        self.attention_mask = tokenized['attention_mask']\n",
    "        self.offset_mapping = tokenized['offset_mapping']\n",
    "        self.q_indices = q_indices\n",
    "        self.original_tokens = self.get_original_tokens(raw_texts)\n",
    "\n",
    "    def get_original_tokens(self, texts):\n",
    "        \"\"\"\n",
    "        Return the original tokens associated with each B x N position. This is important for reconstructing the original text when BPE tokenizers are used.\n",
    "        \n",
    "        Params:\n",
    "            @input_ids: A B x N tensor of input ids.\n",
    "            @offset_mapping: A B x N x 2 tensor of offset mappings. Get from `tokenizer(..., return_offsets_mapping = True)`.\n",
    "\n",
    "        Returns:\n",
    "            A list of length B, each with length N, containing the corresponding original tokens corresponding to the token ID at the same position of input_ids.\n",
    "        \"\"\"\n",
    "        all_token_substrings = []\n",
    "        for i in range(0, self.input_ids.shape[0]):\n",
    "            token_substrings = []\n",
    "            for j in range(self.input_ids.shape[1]): \n",
    "                start_char, end_char = self.offset_mapping[i][j].tolist()\n",
    "                if start_char == 0 and end_char == 0: # When pads, offset_mapping might be [0, 0], so let's store an empty string for those positions.\n",
    "                    token_substrings.append(\"\")\n",
    "                else:\n",
    "                    original_substring = texts[i][start_char:end_char]\n",
    "                    token_substrings.append(original_substring)\n",
    "            \n",
    "            all_token_substrings.append(token_substrings)\n",
    "\n",
    "        return all_token_substrings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {'input_ids': self.input_ids[idx], 'attention_mask': self.attention_mask[idx], 'original_tokens': self.original_tokens[idx], 'q_indices': self.q_indices[idx]}\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function; necessary to return original_tokens in the correct shape \n",
    "    \"\"\"\n",
    "    input_ids = torch.stack([b['input_ids'] for b in batch], dim = 0)\n",
    "    attention_mask = torch.stack([b['attention_mask'] for b in batch], dim = 0)        \n",
    "    original_tokens = [b['original_tokens'] for b in batch]\n",
    "    q_indices = [b['q_indices'] for b in batch]\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'original_tokens': original_tokens, 'q_indices': q_indices}\n",
    "\n",
    "# Must be under max length to confirm nothing was truncated\n",
    "print(\n",
    "    tokenizer(mmlu_df['input_prompt'].tolist(), add_special_tokens = False, max_length = 1024, padding = 'max_length', truncation = True, return_tensors = 'pt')\\\n",
    "        ['attention_mask']\\\n",
    "        .sum(dim = 1)\\\n",
    "        .max()\n",
    ")\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    ReconstructableTextDataset(mmlu_df['input_prompt'].tolist(), mmlu_df['q_ix'].tolist(), tokenizer, max_length = 768),\n",
    "    batch_size = 8,\n",
    "    shuffle = False,\n",
    "    collate_fn = collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59112e7e",
   "metadata": {},
   "source": [
    "## Run first pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a0da3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "system\n",
      "You will be provided with a multiple-choice question, as well as a list of possible answer choices. Respond exactly with: \"The correct answer is {X}\", substituting in X with the code for the correct choice.\n",
      "user\n",
      "Question: A lesion causing compression of the facial nerve at the stylomastoid foramen will cause ipsilateral\n",
      "Choices:\n",
      "(A) paralysis of the facial muscles.\n",
      "(B) paralysis of the facial muscles and loss of taste.\n",
      "(C) paralysis of the facial muscles, loss of taste and lacrimation.\n",
      "(D) paralysis of the facial muscles, loss of taste, lacrimation and decreased salivation.\n",
      "\n",
      "assistant\n",
      "The correct answer is A\n",
      "user\n",
      "Question: The access matrix approach to protection has the difficulty that\n",
      "Choices:\n",
      "(A) the matrix, if stored directly, is large and can be clumsy to manage\n",
      "(B) it is not capable of expressing complex protection requirements\n",
      "(C) deciding whether a process has access to a resource is undecidable\n",
      "(D) there is no way to express who has rights to change the access matrix itself\n",
      "\n",
      "assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "The correct answer is\u001b[32m A\u001b[0m\n",
      "---------\n",
      "system\n",
      "You will be provided with a multiple-choice question, as well as a list of possible answer choices. Respond exactly with: \"The correct answer is {X}\", substituting in X with the code for the correct choice.\n",
      "user\n",
      "Question: A lesion causing compression of the facial nerve at the stylomastoid foramen will cause ipsilateral\n",
      "Choices:\n",
      "(A) paralysis of the facial muscles.\n",
      "(B) paralysis of the facial muscles and loss of taste.\n",
      "(C) paralysis of the facial muscles, loss of taste and lacrimation.\n",
      "(D) paralysis of the facial muscles, loss of taste, lacrimation and decreased salivation.\n",
      "\n",
      "assistant\n",
      "The correct answer is A\n",
      "user\n",
      "Question: An integer c is a common divisor of two integers x and y if and only if c is a divisor of x and c is a divisor of y. Which of the following sets of integers could possibly be the set of all common divisors of two integers?\n",
      "Choices:\n",
      "(A) {-6,-2, -1, 1, 2, 6}\n",
      "(B) {-6, -2, -1, 0, 1, 2, 6}\n",
      "(C) {-6, -3, -2, -1, 1, 2, 3, 6}\n",
      "(D) {-6, -3, -2, -1, 0, 1, 2, 3, 6}\n",
      "\n",
      "assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "The correct answer is\u001b[32m C\u001b[0m\n",
      "---------\n",
      "system\n",
      "You will be provided with a multiple-choice question, as well as a list of possible answer choices. Respond exactly with: \"The correct answer is {X}\", substituting in X with the code for the correct choice.\n",
      "user\n",
      "Question: A lesion causing compression of the facial nerve at the stylomastoid foramen will cause ipsilateral\n",
      "Choices:\n",
      "(A) paralysis of the facial muscles.\n",
      "(B) paralysis of the facial muscles and loss of taste.\n",
      "(C) paralysis of the facial muscles, loss of taste and lacrimation.\n",
      "(D) paralysis of the facial muscles, loss of taste, lacrimation and decreased salivation.\n",
      "\n",
      "assistant\n",
      "The correct answer is A\n",
      "user\n",
      "Question: In the NoNicks operating system, the time required by a single file-read operation has four nonoverlapping components:\n",
      "disk seek time-25 msec\n",
      "disk latency time-8 msec\n",
      "disk transfer time- 1 msec per 1,000 bytes\n",
      "operating system overhead-1 msec per 1,000 bytes + 10 msec\n",
      "In version 1 of the system, the file read retrieved blocks of 1,000 bytes. In version 2, the file read (along with the underlying layout on disk) was modified to retrieve blocks of 4,000 bytes. The ratio of-the time required to read a large file under version 2 to the time required to read the same large file under version 1 is approximately\n",
      "Choices:\n",
      "(A) 1:4\n",
      "(B) 1:3.5\n",
      "(C) 1:1\n",
      "(D) 1.1:1\n",
      "\n",
      "assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "The correct answer is\u001b[32m D\u001b[0m\n",
      "---------\n",
      "system\n",
      "You will be provided with a multiple-choice question, as well as a list of possible answer choices. Respond exactly with: \"The correct answer is {X}\", substituting in X with the code for the correct choice.\n",
      "user\n",
      "Question: A lesion causing compression of the facial nerve at the stylomastoid foramen will cause ipsilateral\n",
      "Choices:\n",
      "(A) paralysis of the facial muscles.\n",
      "(B) paralysis of the facial muscles and loss of taste.\n",
      "(C) paralysis of the facial muscles, loss of taste and lacrimation.\n",
      "(D) paralysis of the facial muscles, loss of taste, lacrimation and decreased salivation.\n",
      "\n",
      "assistant\n",
      "The correct answer is A\n",
      "user\n",
      "Question: You want to cluster 7 points into 3 clusters using the k-Means Clustering algorithm. Suppose after the first iteration, clusters C1, C2 and C3 contain the following two-dimensional points: C1 contains the 2 points: {(0,6), (6,0)} C2 contains the 3 points: {(2,2), (4,4), (6,6)} C3 contains the 2 points: {(5,5), (7,7)} What are the cluster centers computed for these 3 clusters?\n",
      "Choices:\n",
      "(A) C1: (3,3), C2: (4,4), C3: (6,6)\n",
      "(B) C1: (3,3), C2: (6,6), C3: (12,12)\n",
      "(C) C1: (6,6), C2: (12,12), C3: (12,12)\n",
      "(D) C1: (0,0), C2: (48,48), C3: (35,35)\n",
      "\n",
      "assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "The correct answer is\u001b[32m A\u001b[0m\n",
      "---------\n",
      "system\n",
      "You will be provided with a multiple-choice question, as well as a list of possible answer choices. Respond exactly with: \"The correct answer is {X}\", substituting in X with the code for the correct choice.\n",
      "user\n",
      "Question: A lesion causing compression of the facial nerve at the stylomastoid foramen will cause ipsilateral\n",
      "Choices:\n",
      "(A) paralysis of the facial muscles.\n",
      "(B) paralysis of the facial muscles and loss of taste.\n",
      "(C) paralysis of the facial muscles, loss of taste and lacrimation.\n",
      "(D) paralysis of the facial muscles, loss of taste, lacrimation and decreased salivation.\n",
      "\n",
      "assistant\n",
      "The correct answer is A\n",
      "user\n",
      "Question: Any set of Boolean operators that is sufficient to represent all Boolean expressions is said to be complete. Which of the following is NOT complete?\n",
      "Choices:\n",
      "(A) {AND, NOT}\n",
      "(B) {NOT, OR}\n",
      "(C) {AND, OR}\n",
      "(D) {NAND}\n",
      "\n",
      "assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "The correct answer is\u001b[32m C\u001b[0m\n",
      "PPL: 12.292810440063477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [26:15<00:00, 15.75s/it]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run forward passes - store token level dataframe and topk-level dataframe\n",
    "\"\"\"\n",
    "sample_dfs = []\n",
    "topk_dfs = []\n",
    "\n",
    "for batch_ix, batch in tqdm(enumerate(test_dl), total = len(test_dl)):\n",
    "\n",
    "    input_ids = batch['input_ids'].to(main_device)\n",
    "    attention_mask = batch['attention_mask'].to(main_device)\n",
    "    original_tokens = batch['original_tokens']\n",
    "    q_indices = batch['q_indices']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = run_model_return_topk(model, input_ids, attention_mask, return_hidden_states = True)\n",
    "\n",
    "    # Check no bugs by validating output/perplexity\n",
    "    if batch_ix == 0:\n",
    "        loss = ForCausalLMLoss(output['logits'], torch.where(input_ids == tokenizer.pad_token_id, torch.tensor(-100), input_ids), model.config.vocab_size).detach().cpu().item()\n",
    "        for i in range(min(5, input_ids.size(0))):\n",
    "            decoded_input = tokenizer.decode(input_ids[i, :], skip_special_tokens = True)\n",
    "            next_token_id = torch.argmax(output['logits'][i, -1, :]).item()\n",
    "            print('---------\\n' + decoded_input + colored(tokenizer.decode([next_token_id], skip_special_tokens = False).replace('\\n', '<lb>'), 'green'))\n",
    "        print(f\"PPL:\", torch.exp(torch.tensor(loss)).item())\n",
    "    \n",
    "    # Create mapping of seq_ix to q_ix, so we can drop batch_ix and seq_ix and return q_ix\n",
    "    seq_to_q_map = pd.DataFrame({'sequence_ix': list(range(0, input_ids.shape[0])), 'q_ix': batch['q_indices']})\n",
    "\n",
    "    # Convert original tokens back to (seq_ix, token_ix) level for later storage\n",
    "    original_tokens_df = pd.DataFrame(\n",
    "        [(seq_i, tok_i, tok) for seq_i, tokens in enumerate(original_tokens) for tok_i, tok in enumerate(tokens)], \n",
    "        columns = ['sequence_ix', 'token_ix', 'token']\n",
    "    )\n",
    "\n",
    "    # Final token outputs - get the decoded outputs for the final tokens only, since convert_outputs_to_df only returns output tokens as IDs\n",
    "    question_token_outputs = tokenizer.batch_decode(torch.argmax(output['logits'][:, -1, :], dim = 1).tolist())\n",
    "    question_token_outputs_df = pd.DataFrame({'sequence_ix': list(range(0, input_ids.shape[0])), 'question_output_token': question_token_outputs})\n",
    "\n",
    "    # Create sample (token) level dataframe\n",
    "    sample_df =\\\n",
    "        convert_outputs_to_df(input_ids, attention_mask, output['logits'])\\\n",
    "        .merge(question_token_outputs_df, how = 'left', on = ['sequence_ix'])\\\n",
    "        .merge(original_tokens_df, how = 'left', on = ['token_ix', 'sequence_ix'])\\\n",
    "        .merge(seq_to_q_map, how = 'inner', on = ['sequence_ix'])\\\n",
    "        .drop(columns = ['sequence_ix'])\n",
    "    \n",
    "    # Create topk x layer_ix x sample level dataframe\n",
    "    topk_df =\\\n",
    "        convert_topk_to_df(input_ids, attention_mask, output['all_topk_experts'], output['all_topk_weights'])\\\n",
    "        .merge(seq_to_q_map, how = 'inner')\\\n",
    "        .drop(columns = ['sequence_ix', 'token_id'])\n",
    "\n",
    "    sample_dfs.append(sample_df)\n",
    "    topk_dfs.append(topk_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b99285a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Save data\n",
    "\"\"\"\n",
    "sample_df = pd.concat(sample_dfs).merge(mmlu_df, how = 'inner', on = 'q_ix').drop(columns = 'input_prompt')\n",
    "topk_df = pd.concat(topk_dfs)\n",
    "\n",
    "sample_df.to_csv(f'{model_prefix}-samples.csv', mode = 'w', index = False)\n",
    "topk_df.to_csv(f'{model_prefix}-topks.csv', mode = 'w', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fa8ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Quick check for accuracy\n",
    "\"\"\"\n",
    "pd.concat(sample_dfs).merge(mmlu_df, how = 'inner', on = 'q_ix')\\\n",
    "    .groupby(['q_ix', 'lang_ix', 'domain_ix', 'source_id', 'domain', 'question_output_token', 'answer_char'], as_index = False)\\\n",
    "    .agg(n_tokens = ('q_ix', 'count'))\\\n",
    "    .assign(is_correct = lambda df: np.where(df['question_output_token'].str.strip() == df['answer_char'], 1, 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
